idx = unlist(lapply(temp[,1], function(x){which(p_meta[,1] == x)}))
p_meta[idx,] = hot_to_r(input$hot4)
}
if(!is.null(input$hot5)){
temp = hot_to_r(input$hot5)
idx = unlist(lapply(temp[,1], function(x){which(p_meta[,1] == x)}))
p_meta[idx,] = hot_to_r(input$hot5)
}
} else {
if (is.null(values[["p_meta"]]))
p_meta <- p_meta
else
p_meta <- values[["p_meta"]]
}
# ## metadata already entered
if(!is.null(input$upload)){
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "file_type")] = ifelse(values$ext == "nc", "netcdf", "text delim")
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "path")] = values$file_path
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "extention")] = values$ext
}
if(input$source != "new source"){
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "source")] = input$source
}
if(input$method != "new method"){
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "Method")] = input$method
}
if(!is.null(input$hot_source) & input$source == "new source"){
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "source")] = values$new_source$source
}
if(!is.null(input$hot_method) & input$method == "new method"){
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "Method")] = values$new_method$Method
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "analysis_type")] = values$new_method$analysis_type
}
values[["p_meta"]] <- p_meta
})
# possible selection options for fixed when have time later. Including check on EXPOCODE
output$hot1 =  renderRHandsontable({
p_meta = values[["p_meta"]]
tab = p_meta[1:7,] %>% filter(`Data stream/s` == "all" | grepl(input$stream, `Data stream/s`, ignore.case = T))
rhandsontable(tab, width = 1200) %>% hot_col(c(1:2,4:5), readOnly = TRUE) %>% hot_table(highlightRow = TRUE) %>%  hot_context_menu(allowRowEdit = FALSE, allowColEdit = FALSE) %>%
hot_cols(colWidths = c(200, 100, 200, 250, 400)) %>% hot_col("User input", renderer = col.hi.render)})
output$hot2 =  renderRHandsontable({
p_meta = values[["p_meta"]]
tab = p_meta[8:15,] %>% filter(`Data stream/s` == "all" | grepl(input$stream, `Data stream/s`, ignore.case = T))
rhandsontable(tab, width = 1200, row_highlight = c(1,2)) %>% hot_col(c(1:2,4:5), readOnly = TRUE) %>% hot_table(highlightRow = TRUE) %>%  hot_context_menu(allowRowEdit = FALSE, allowColEdit = FALSE) %>% hot_cols(colWidths = c(200, 100, 200, 250, 400)) %>% hot_col("User input", renderer = col.hi.render)})
output$hot3 =  renderRHandsontable({
p_meta = values[["p_meta"]]
tab = p_meta[16:41,] %>% filter(`Data stream/s` == "all" | grepl(input$stream, `Data stream/s`, ignore.case = T))
rhandsontable(tab, width = 1200) %>% hot_col(c(1:2,4:5), readOnly = TRUE) %>% hot_table(highlightRow = TRUE) %>%  hot_context_menu(allowRowEdit = FALSE, allowColEdit = FALSE) %>%
hot_cols(colWidths = c(200, 100, 200, 250, 400)) %>% hot_col("User input", renderer = col.hi.render)})
output$hot4 =  renderRHandsontable({
p_meta = values[["p_meta"]]
tab = p_meta[42:61,] %>% filter(`Data stream/s` == "all" | grepl(input$stream, `Data stream/s`, ignore.case = T))
rhandsontable(tab, width = 1200) %>% hot_col(c(1:2,4:5), readOnly = TRUE) %>% hot_table(highlightRow = TRUE) %>%  hot_context_menu(allowRowEdit = FALSE, allowColEdit = FALSE) %>%
hot_cols(colWidths = c(200, 100, 200, 250, 400)) %>% hot_col("User input", renderer = col.hi.render)})
output$hot5 =  renderRHandsontable({
p_meta = values[["p_meta"]]
tab = p_meta[62:105,] %>% filter(`Data stream/s` == "all" | grepl(input$stream, `Data stream/s`, ignore.case = T))
rhandsontable(tab, width = 1200) %>% hot_col(c(1:2,4:5), readOnly = TRUE) %>% hot_table(highlightRow = TRUE) %>%  hot_context_menu(allowRowEdit = FALSE, allowColEdit = FALSE) %>%
hot_cols(colWidths = c(200, 100, 200, 250, 400)) %>% hot_col("User input", renderer = col.hi.render)})
####### Run BIO-MATE ##########
observeEvent(input$runBIOMATE, {
req(input$stream, input$upload)
process_meta = t(values$p_meta[,3])
colnames(process_meta) = values$p_meta[,1]
out_dir = file.path(values$file_path,"meta")
if(!file.exists(out_dir))
{dir.create(out_dir)}
write.csv(process_meta, file.path(out_dir, paste(input$stream, "_meta.csv", sep = "")))
if(input$stream == "PROF"){
BIOMATE::PROF_to_WHPE(outdir,file.path(local_out,"reformatted_data" ))
}
if(input$stream == "PIG"){BIOMATE::PIG_to_WHPE(outdir,file.path(local_out,"reformatted_data" ))}
})
# WHEN WRITING new data TO GITHUB
## add new source and method info to data
## add new citations to bib
## save processing metadata
## save reformatted files
####### Download Files ########
# output$download <- downloadHandler(
#   filename = function(){
#     paste0(input$text,".zip")
#
#   },
#   content = function(file){
#     #go to a temp dir to avoid permission issues
#     owd <- setwd(tempdir())
#     on.exit(setwd(owd))
#     files <- NULL;
#
#     #loop through the sheets
#     for (i in 1:input$sheet){
#       #write each sheet to a csv file, save the name
#       fileName <- paste(input$text,"_0",i,".csv",sep = "")
#       write.table(data()$wb[i],fileName,sep = ';', row.names = F, col.names = T)
#       files <- c(fileName,files)
#     }
#     #create the zip file
#     zip(file,files)
#   }
# )
}
shinyApp(ui, server)
p_meta = data.frame("variable"= character(), "stream" = character(), "description" = character(), "input"= character())
p_meta = p_meta %>%
add_row(variable = "file_type", stream = "all", description = "The format of the file/s.", input = "text delim or netcdf") %>%
add_row(variable = "path", stream = "all", description = "A path to where the file/s is stored.", input = "A pathname that is R compatible") %>%
add_row(variable = "extention", stream = "all", description = "The extension of the file/s.", input = "text delim or netcdf") %>%
add_row(variable = "delim", stream = "all", description = "Only fill if rectangular text-delimited file/s.", input = "rect") %>%
add_row(variable = "header_sep", stream = "all", description = "A separator used in headers of the file. Headers often store location data in profiling datasets and need extraction. Can be left empty.", input = "colon, comma, dash, equals, space") %>%
add_row(variable = "missing_value", stream = "all", description = "The value or character used to indicate a missing value.", input = "value") %>%
add_row(variable = "not_detected", stream = "PIG, POC", description = "The value or character used to indicate a variable was not detected in analysis.", input = "value") %>%
add_row(variable = "EXPOCODE", stream = "all", description = "The EXPOCODE of the voyage associated with the data.", input = "12-digit code") %>%
add_row(variable = "source", stream = "all", description = "The data repository the data files were sourced from.", input = "The short name of the data repository used within BIO-MATE. See https://github.com/KimBaldry/BIO-MATE/product_data/supporting_information/BIOMATE_SOURCES.txt.") %>%
add_row(variable = "PI", stream = "all", description = "The principle investigator/s responsible for the published dataset.", input = "Names sepparated by a dash") %>%
add_row(variable = "Institution", stream = "all", description = "The institution/s who collected the data.", input = "Names sepparated by a dash") %>%
add_row(variable = "contact", stream = "all", description = "A contact for the published dataset.", input = "E-mail address") %>%
add_row(variable = "citation", stream = "all", description = "The BIO-MATE citation tag/s used to reference a BibTEX entry for the published dataset.", input = "A BIO-MATE citation tag") %>%
add_row(variable = "analysis_type", stream = "PIG, POC", description = "The type of analysis used on water samples for the published dataset.", input = "A code to reference an analysis type. See https://github.com/KimBaldry/BIO-MATE/product_data/supporting_information/BIOMATE_METHODS.txt") %>%
add_row(variable = "Method", stream = "PIG, POC", description = "The method used to analyse water samples for the published dataset.", input = "A code to reference a method. See https://github.com/KimBaldry/BIO-MATE/product_data/supporting_information/BIOMATE_METHODS.txt") %>%
add_row(variable = "TZ", stream = "all", description = "The time zone for date and time information.", input = "Time zone code") %>%
add_row(variable = "STNNBR", stream = "all", description = "The name of the variable for the station number of the profiling staation.", input = "Text. If recorded in header use header-[variable].") %>%
add_row(variable = "CASTNO", stream = "all", description = "The name of the variable for the cast number at the profiling station.", input = "Text. If recorded in header use header-[variable].") %>%
add_row(variable = "DATE", stream = "PROF", description = "The name of the variable for the date of the profiling cast.", input = "Text. If recorded in header use header-[variable].") %>%
add_row(variable = "DATE_analyser", stream = "PIG, POC", description = "The name of the variable for date of observation recorded by the analyser.", input = "Text. If recorded in header use header-[variable].") %>%
add_row(variable = "DATE_format", stream = "PROF", description = "Format for DATE.", input = "A format string code. See strptime in R for codes.") %>%
add_row(variable = "DATE_analyser_format", stream = "PIG, POC", description = "Format for DATE_analyser.", input = "A format string code. See strptime in R for codes.") %>%
add_row(variable = "TIME_s", stream = "PROF", description = "The name of the variable for time at the start of teh profiling cast.", input = "Text. If recorded in header use header-[variable].") %>%
add_row(variable = "TIME_b", stream = "PROF", description = "The name of the variable for time at the bottom of the profiling cast.", input = "Text. If recorded in header use header-[variable].") %>%
add_row(variable = "TIME_e", stream = "PROF", description = "The name of the variable for time at the end of the profiling cast.", input = "Text. If recorded in header use header-[variable].") %>%
add_row(variable = "TIME_analyser", stream = "PIG, POC", description = "The name of the variable for time of observation recorded by the analyser.  If recorded in header use header-[variable].", input = "Text") %>%
add_row(variable = "TIME_format", stream = "PROF", description = "Format for TIME.", input = "A format string code. See strptime in R for codes.") %>%
add_row(variable = "TIME_b_format", stream = "PROF", description = "Format for TIME_b, if different to TIME_format.", input = "A format string code. See strptime in R for codes.") %>%
add_row(variable = "TIME_analyser_format", stream = "PIG, POC", description = "Format of TIME_analyser.", input = "A format string code. See strptime in R for codes.") %>%
add_row(variable = "LATITUDE_s", stream = "PROF", description = "The name of the variable for latitude at the start of the profiling cast.", input = "Text") %>%
add_row(variable = "LATITUDE_b", stream = "PROF", description = "The name of the variable for latitude at the bottom of the profiling cast.", input = "Text") %>%
add_row(variable = "LATITUDE_e", stream = "PROF", description = "The name of the variable for latitude at the end of the profiling cast.", input = "Text") %>%
add_row(variable = "LONGITUDE_s", stream = "PROF", description = "The name of the variable for longitude at the start of the profiling cast.", input = "Text") %>%
add_row(variable = "LONGITUDE_b", stream = "PROF", description = "The name of the variable for longitude at the bottom of the profiling cast.", input = "Text") %>%
add_row(variable = "LONGITUDE_e", stream = "PROF", description = "The name of the variable for longitude at the end of the profiling cast.", input = "Text") %>%
add_row(variable = "LAT_analyser", stream = "PIG, POC", description = "The name of the variable for latitude recorded by the analyser.", input = "Text") %>%
add_row(variable = "LON_analyser", stream = "PIG, POC", description = "The name of the variable for longitude recorded by the analyser.", input = "Text") %>%
add_row(variable = "POSITION_format", stream = "all", description = "The format of latitude and longitude data.", input = "A string describing the format made up of %deg (degrees), %min (minutes), %sec (seconds) and %pos (for N/S/E/W specification)") %>%
add_row(variable = "Sample_ID", stream = "PIG, POC", description = "The name of the variable containing sample identification.", input = "Text") %>%
add_row(variable = "BOTTLE", stream = "PIG, POC", description = "The name of the variable containing bottle identifications.", input = "Text") %>%
add_row(variable = "Underway_ID", stream = "PIG, POC", description = "How underway samples are identified within the dataset. Leave blank if there are no underway values within the dataset.", input = "[variable name]-[value] or all") %>%
add_row(variable = "CTDPRS", stream = "PROF", description = "The name of the variable for pressure collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDPRS_u", stream = "PROF", description = "The units for pressure collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDTMP", stream = "PROF", description = "The name of the variable for temperature collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDTMP_u", stream = "PROF", description = "The units for temperature collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDSAL", stream = "PROF", description = "The name of the variable for salinity collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDSAL_u", stream = "PROF", description = "The units for salinity collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDOXY", stream = "PROF", description = "The name of the variable for oxygen collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDOXY_u", stream = "PROF", description = "The units for oxygen collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDFLUOR", stream = "PROF", description = "The name of the variable for fluorescence collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDFLUOR_u", stream = "PROF", description = "The units for fluorescence collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDBEAMCP", stream = "PROF", description = "The name of the variable for beam attenuation collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDBEAMCP_u", stream = "PROF", description = "The units for beam attenuation collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDBBP700", stream = "PROF", description = "The name of the variable for optical backscatter (700 nm) collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDBBP700_u", stream = "PROF", description = "The units for optical backscatter (700 nm) collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDXMISS", stream = "PROF", description = "The name of the variable for transmittance collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDXMISS_u", stream = "PROF", description = "The units for transmittance collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDPAR", stream = "PROF", description = "The name of the variable for photosyntheitically active radiation collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDPAR_u", stream = "PROF", description = "The units for photosyntheitically active radiation collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDNITRATE", stream = "PROF", description = "The name of the variable for oxygen collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "CTDNITRATE_u", stream = "PROF", description = "The units for oxygen collected by the profiling sensor.", input = "Text") %>%
add_row(variable = "DEPTH", stream = "PIG,POC", description = "The name of the variable for depth of observation recorded by the analyser.", input = "Text") %>%
add_row(variable = "PIG_u", stream = "PIG", description = "The units for pigment measurements recorded by the analyser.", input = "Text") %>%
add_row(variable = "FCHLORA", stream = "PIG", description = "The name of the variable for fluorometrically derived chlorophyll.", input = "Text") %>%
add_row(variable = "FPHEO", stream = "PIG", description = "The name of the variable for fluorometrically derived phaeopigments.", input = "Text") %>%
add_row(variable = "FPHYTIN", stream = "PIG", description = "The name of the variable for fluorometrically derived phaeophytin.", input = "Text") %>%
add_row(variable = "TCHLA", stream = "PIG", description = "The name of the variable for HPLC derived total chlorophyll a.", input = "Text") %>%
add_row(variable = "TACC", stream = "PIG", description = "The name of the variable for HPLC derived total accessory pigments.", input = "Text") %>%
add_row(variable = "DVChla", stream = "PIG", description = "The name of the variable for HPLC derived divinyl chlorophyll a.", input = "Text") %>%
add_row(variable = "Chla", stream = "PIG", description = "The name of the variable for HPLC derived chlorophyll a.", input = "Text") %>%
add_row(variable = "Chla_ide", stream = "PIG", description = "The name of the variable for HPLC derived chlorophyllide.", input = "Text") %>%
add_row(variable = "Chla_allom", stream = "PIG", description = "The name of the variable for HPLC derived chlorophyll a allomers.", input = "Text") %>%
add_row(variable = "Chla_prime", stream = "PIG", description = "The name of the variable for HPLC derived chlorophyll a prime.", input = "Text") %>%
add_row(variable = "Chlb", stream = "PIG", description = "The name of the variable for HPLC derived chlorophyll b.", input = "Text") %>%
add_row(variable = "DVChlb", stream = "PIG", description = "The name of the variable for HPLC derived divinyl chlorophyll b.", input = "Text") %>%
add_row(variable = "Chlc", stream = "PIG", description = "The name of the variable for HPLC derived chlorophyll c.", input = "Text") %>%
add_row(variable = "Chlc1_Chlc2_Mg_3_8_divinyl_pheoporphyrin_a5", stream = "PIG", description = "The name of the variable for HPLC derived chlorophyll c1 + chlorophyll c2 + Mg 3,8 divinyl pheoporphyrin a5.", input = "Text") %>%
add_row(variable = "Chlc1", stream = "PIG", description = "The name of the variable for HPLC derived chlorophyll c1.", input = "Text") %>%
add_row(variable = "Chlc1_like", stream = "PIG", description = "The name of the variable for HPLC derived chlorophyll c1-like.", input = "Text") %>%
add_row(variable = "Chlc2", stream = "PIG", description = "The name of the variable for HPLC derived chlorophyll c2.", input = "Text") %>%
add_row(variable = "Chlc1_Chlc2", stream = "PIG", description = "The name of the variable for HPLC derived chlorophyll c1 + chlorophyll c2.", input = "Text") %>%
add_row(variable = "Chlc3", stream = "PIG", description = "The name of the variable for HPLC derived chlorophyll c3.", input = "Text") %>%
add_row(variable = "MgDVP", stream = "PIG", description = "The name of the variable for HPLC derived Mg 2,4 divinyl pheoporphyrin a5 monomethyl ester.", input = "Text") %>%
add_row(variable = "19Hex", stream = "PIG", description = "The name of the variable for HPLC derived 19’hexanoyloxyfucoxanthin.", input = "Text") %>%
add_row(variable = "19But", stream = "PIG", description = "The name of the variable for HPLC derived 19’butanoyloxyfucoxanthin.", input = "Text") %>%
add_row(variable = "Fucox", stream = "PIG", description = "The name of the variable for HPLC derived fucoxanthin.", input = "Text") %>%
add_row(variable = "Perid", stream = "PIG", description = "The name of the variable for HPLC derived peridinin.", input = "Text") %>%
add_row(variable = "Prasino", stream = "PIG", description = "The name of the variable for HPLC derived prasinoxanthin.", input = "Text") %>%
add_row(variable = "Allox", stream = "PIG", description = "The name of the variable for HPLC derived alloxanthin.", input = "Text") %>%
add_row(variable = "Lutein", stream = "PIG", description = "The name of the variable for HPLC derived lutein.", input = "Text") %>%
add_row(variable = "Zeax", stream = "PIG", description = "The name of the variable for HPLC derived zeaxanthin.", input = "Text") %>%
add_row(variable = "Zea_Lut", stream = "PIG", description = "The name of the variable for HPLC derived zeaxanthin + lutein.", input = "Text") %>%
add_row(variable = "Violax", stream = "PIG", description = "The name of the variable for HPLC derived violaxanthin.", input = "Text") %>%
add_row(variable = "Alpha_car", stream = "PIG", description = "The name of the variable for HPLC derived alpha carotene.", input = "Text") %>%
add_row(variable = "Beta_car", stream = "PIG", description = "The name of the variable for HPLC derived beta carotene.", input = "Text") %>%
add_row(variable = "Gamma_car", stream = "PIG", description = "The name of the variable for HPLC derived gamma carotene.", input = "Text") %>%
add_row(variable = "Epsilon_car", stream = "PIG", description = "The name of the variable for HPLC derived epsilon carotene.", input = "Text") %>%
add_row(variable = "Alpha_Beta_car", stream = "PIG", description = "The name of the variable for HPLC derived alpha + beta carotene.", input = "Text") %>%
add_row(variable = "Neox", stream = "PIG", description = "The name of the variable for HPLC derived neoxanthin.", input = "Text") %>%
add_row(variable = "DD", stream = "PIG", description = "The name of the variable for HPLC derived diadinoxanthin.", input = "Text") %>%
add_row(variable = "DT", stream = "PIG", description = "The name of the variable for HPLC derived diatoxanthin.", input = "Text") %>%
add_row(variable = "Viol_Neox", stream = "PIG", description = "The name of the variable for HPLC derived violaxanthin + neoxanthin.", input = "Text") %>%
add_row(variable = "Phaeopigments", stream = "PIG", description = "The name of the variable for HPLC derived bulk phaeopigments.", input = "Text") %>%
add_row(variable = "Phide_a", stream = "PIG", description = "The name of the variable for HPLC derived phaeophorbide a.", input = "Text") %>%
add_row(variable = "Phytin_a", stream = "PIG", description = "The name of the variable for HPLC derived phaeophytin a.", input = "Text")
colnames(p_meta) = c("Processing metadata variable", "Data stream/s","Description", "Input Guide" )
save(p_meta, file = "metadata_info.RData")
View(p_meta)
load(url("https://github.com/KimBaldry/BIO-MATE/raw/main/data_descriptor_paper/metadata_info.RData"))
View(p_meta)
library(shiny)
library(shinyWidgets)
library(dplyr)
library(rhandsontable)
library(BIOMATE)
load(url("https://github.com/KimBaldry/BIO-MATE/raw/main/data_descriptor_paper/metadata_info.RData"))
load(url("https://github.com/KimBaldry/BIO-MATE/raw/main/product_data/next_version/package_data/BIOMATE.rda"))
local_out = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/BIO-MATE/product_data/next_version"
p_meta$`User input` = ""
p_meta = p_meta[,c(1:2,5,4:3)]
#To implement:
# add data citation tags
# check existing EXPOCODES
# show citations existing for EXPOCODE
# show available data for EXPOCODE
# integrate uploaded citations to bib object DONE
# integrate uploaded method citations to bib object
# when running biomate upload metadata to github including new_source and new_method info and new bib objects
# run split file code
# 1. user interface object
ui <- navbarPage(
"BIO-SHARE",
################# Upload published data ###########################
tabPanel("Upload published data",
fluidPage(
p("Upload published data files. BIO-SHARE can only handle processing one data stream at a time."),
fileInput("upload", NULL, accept = c(".csv", ".tsv",".tab",".nc",".all",".sb",".txt"),multiple = T),
verbatimTextOutput("error1"),
#selectInput("run_expocode", label = "EXPOCODE", choices(c("new", ))) # reference to existing expocodes in package metadata
selectInput("stream", label = "Data stream to ingest", choices = c("PROF", "PIG")),
p("Information is needed to properly cite the data"),
## Source Information
selectInput("source",label = "Source citation", choices = c("new source",source_info$source)), # translate to p_meta
conditionalPanel(condition = "input.source == 'new source'",
rHandsontableOutput("hot_source")),
checkboxInput("showsource","Show existing BIO-MATE data sources", value = F),
conditionalPanel(condition = "input.showsource == true", dataTableOutput("source_info")),
## Method information
conditionalPanel(condition = "input.stream == 'PIG'",
selectInput("method",label = "Method citation", choices = c("new method",method_info$Method)), # translate to p_meta
conditionalPanel(condition = "input.method == 'new method'",
rHandsontableOutput("hot_method")),
checkboxInput("showmethod","Show existing BIO-MATE pigment measurement methods"),
conditionalPanel(condition = "input.showmethod == true", dataTableOutput("method_info"))),
fileInput("upload_bibtex", "BibTEX file/s", accept = c(".bib"),multiple = T)
)),
########### Split files ########################################
tabPanel("Split files",
fluidPage(
p("Fill in the below information to split your file. Note to use the split function for multiple streams, enter the information for one data stream then select run. After this do the same for the next data stream."),
actionButton("split", label = "Run"),
textInput("split_delim",label = "File Delimiter"),
p("The text delimiter of the file to be split. Put the delimeter symbol here, remember tab is /t."),
numericInput("split_line_start", "Header line", value = 1, min = 1, max = 100),
p("The line in which the data table starts (i.e. the line the variable headers are on)"),
selectInput("expo_split", "Split by EXPOCODES", choices = c("T","F"), selected = "T"),
fileInput("ex_lookup", NULL, accept = c(".csv"),multiple = F),
p("Set to T if working with EXPOCODE synonyms data to split further into EXPOCODES. Note you need a supplementry comma delimited file with two columns. The first column named 'EXPOCODE' should contain the EXPOCODE as used in the data aggregation. The second column named 'synonym' muct contain the EXPOCODE synonym that appears in the file."),
textInput("synonym_var_name", "Variable with EXPOCODE synonyms"),
p("Only needed when Split by EXPOCODES = T. The variable, containing EXPOCODE synonyms, that the file is to be split by."),
selectInput("station_split", "Split by station", choices = c("T","F"), selected = "T"),
p("Set to T if working with PROF/CTD data to split further into profileing stations."),
textInput("station_var_name", "Variable with station ID"),
p("Only needed if Split by station = T. The variable containing station IDs"),
selectInput("fillcell", "Fill cells", choices = c("T","F"), selected = "F"),
p("logical. If TRUE then in case the rows have unequal length, blank fields are implicitly added. See 'fill' and 'Details' in 'read.table' for more information.")
)),
### Enter metadata #####################################################
tabPanel("Enter metadata",
fluidPage(#p("EXPOCODE metadata") # check dates and ship to see if exists in system
p("File format information"),
rHandsontableOutput("hot1"),
p("Data aquisition information"),
rHandsontableOutput("hot2"),
p("Location Data information"),
rHandsontableOutput("hot3"),
conditionalPanel(condition = "input.stream == 'PROF'",p("Profiling sensor data information"),
rHandsontableOutput("hot4")),
conditionalPanel(condition = "input.stream == 'PIG'", p("Pigment and POC data information"),
rHandsontableOutput("hot5"))
)
),
tabPanel("Run BIOMATE",
fluidPage(
actionButton("runBIOMATE", label = "Run BIO-MATE")
)
),
tabPanel("Upload to GitHub"
),
tabPanel("Download data files",
fluidPage(
downloadButton("download")
)
)
)
################ 2.server function #########################################################
# example here https://cran.r-project.org/web/packages/rhandsontable/vignettes/intro_rhandsontable.html
col.hi.render = "
function(instance, td) {
Handsontable.renderers.TextRenderer.apply(this, arguments);
td.style.background = 'lightblue';
}"
server <- function(input, output, session){
# check existence of EXPOCODE and stream data in the system
values <- reactiveValues()
############## Upload published data ####################
observeEvent(input$upload,{
ext <- tools::file_ext(input$upload$name)
values$ext <- paste(".",ext,sep = "")
values$file_path = unique(dirname(input$upload$datapath))
output$error1 <- renderText({
validate(need(all(ext %in% c("csv", "tsv","tab","nc","all","sb","txt")),"Invalid file; Please upload a supported file: .all, .sb, .csv, .tab, .txt, .nc. Submit an issue to https://github.com/KimBaldry/BIO-MATE if you would like another file format supported in BIO-MATE."))
})
})
## sourceinfomation
output$source_info = renderDataTable(source_info)
new_source = data.frame("source" = character(), "citations"= character(), "url"= character(), "aknowledgement" = character(), stringsAsFactors = F)
new_source[1,] =  NA
observe({
if(!is.null(input$hot_source)){
new_source = hot_to_r(input$hot_source)
} else {
if (is.null(values[["new_source"]]))
new_source <- new_source
else
new_source <- values[["new_source"]]
}
values[["new_source"]] <- new_source
})
output$hot_source= renderRHandsontable(rhandsontable(new_source))
output$source_info = renderDataTable(source_info)
## Method informaton
new_method = data.frame("analysis_type" = character(), "Method"= character(), "citation"= character(), "long_AT" = character(), stringsAsFactors = F)
new_method[1,] =  NA
values <- reactiveValues()
observe({
if(!is.null(input$hot_method)){
new_method = hot_to_r(input$hot_method)
} else {
if (is.null(values[["new_method"]]))
new_method <- new_method
else
new_method <- values[["new_method"]]
}
values[["new_method"]] <- new_method
})
output$hot_method = renderRHandsontable(rhandsontable(new_method))
output$method_info = renderDataTable(method_info)
### read BibTEX files
observeEvent(input$upload_bibtex, {
combined_bib <- ""
for (path_to_bib_file in input$upload_bibtex) {
fileCon <- file(path_to_bib_file)
content <- readLines(fileCon)
close(fileCon)
combined_bib <- paste0(combined_bib, "\n", "\n", trimws(paste0(content, collapse="\n")))
}
bibpath = unique(dirname(input$upload_bibtex))
# write temp file
cat(combined_bib, file=file.path(unique(dirname(input$upload_bibtex)),"BIO-MATE_references.bib"), "\n")
# create bib object from temp file
values$new_bib = read.bib(file.path(bibpath,"BIO-MATE_references.bib"))
})
############## Split data ######################
observeEvent(input$split,{
req(input$upload)
split_delim_file(dirname(values$file_path), input$upload$name, input$delim, input$line_start, input$expo_split, input$synonym_var_name, input$station_split, input$station_var_name, input$fillcell)
values$filepaths = file.path(values$filepaths,"split")
})
#### Enter Metadata ########
observe({
if(any(!is.null(input$hot1), !is.null(input$hot2), !is.null(input$hot3), !is.null(input$hot4), !is.null(input$hot5))){
if(!is.null(input$hot1)){
temp = hot_to_r(input$hot1)
idx = unlist(lapply(temp[,1], function(x){which(p_meta[,1] == x)}))
p_meta[idx,] = hot_to_r(input$hot1)
}
if(!is.null(input$hot2)){
temp = hot_to_r(input$hot2)
idx = unlist(lapply(temp[,1], function(x){which(p_meta[,1] == x)}))
p_meta[idx,] = hot_to_r(input$hot2)
}
if(!is.null(input$hot3)){
temp = hot_to_r(input$hot3)
idx = unlist(lapply(temp[,1], function(x){which(p_meta[,1] == x)}))
p_meta[idx,] = hot_to_r(input$hot3)
}
if(!is.null(input$hot4)){
temp = hot_to_r(input$hot4)
idx = unlist(lapply(temp[,1], function(x){which(p_meta[,1] == x)}))
p_meta[idx,] = hot_to_r(input$hot4)
}
if(!is.null(input$hot5)){
temp = hot_to_r(input$hot5)
idx = unlist(lapply(temp[,1], function(x){which(p_meta[,1] == x)}))
p_meta[idx,] = hot_to_r(input$hot5)
}
} else {
if (is.null(values[["p_meta"]]))
p_meta <- p_meta
else
p_meta <- values[["p_meta"]]
}
# ## metadata already entered
if(!is.null(input$upload)){
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "file_type")] = ifelse(values$ext == "nc", "netcdf", "text delim")
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "path")] = values$file_path
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "extention")] = values$ext
}
if(input$source != "new source"){
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "source")] = input$source
}
if(input$method != "new method"){
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "Method")] = input$method
}
if(!is.null(input$hot_source) & input$source == "new source"){
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "source")] = values$new_source$source
}
if(!is.null(input$hot_method) & input$method == "new method"){
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "Method")] = values$new_method$Method
p_meta$`User input`[which(p_meta$`Processing metadata variable` == "analysis_type")] = values$new_method$analysis_type
}
values[["p_meta"]] <- p_meta
})
# possible selection options for fixed when have time later. Including check on EXPOCODE
output$hot1 =  renderRHandsontable({
p_meta = values[["p_meta"]]
tab = p_meta[1:7,] %>% filter(`Data stream/s` == "all" | grepl(input$stream, `Data stream/s`, ignore.case = T))
rhandsontable(tab, width = 1200) %>% hot_col(c(1:2,4:5), readOnly = TRUE) %>% hot_table(highlightRow = TRUE) %>%  hot_context_menu(allowRowEdit = FALSE, allowColEdit = FALSE) %>%
hot_cols(colWidths = c(200, 100, 200, 250, 400)) %>% hot_col("User input", renderer = col.hi.render)})
output$hot2 =  renderRHandsontable({
p_meta = values[["p_meta"]]
tab = p_meta[8:15,] %>% filter(`Data stream/s` == "all" | grepl(input$stream, `Data stream/s`, ignore.case = T))
rhandsontable(tab, width = 1200, row_highlight = c(1,2)) %>% hot_col(c(1:2,4:5), readOnly = TRUE) %>% hot_table(highlightRow = TRUE) %>%  hot_context_menu(allowRowEdit = FALSE, allowColEdit = FALSE) %>% hot_cols(colWidths = c(200, 100, 200, 250, 400)) %>% hot_col("User input", renderer = col.hi.render)})
output$hot3 =  renderRHandsontable({
p_meta = values[["p_meta"]]
tab = p_meta[16:41,] %>% filter(`Data stream/s` == "all" | grepl(input$stream, `Data stream/s`, ignore.case = T))
rhandsontable(tab, width = 1200) %>% hot_col(c(1:2,4:5), readOnly = TRUE) %>% hot_table(highlightRow = TRUE) %>%  hot_context_menu(allowRowEdit = FALSE, allowColEdit = FALSE) %>%
hot_cols(colWidths = c(200, 100, 200, 250, 400)) %>% hot_col("User input", renderer = col.hi.render)})
output$hot4 =  renderRHandsontable({
p_meta = values[["p_meta"]]
tab = p_meta[42:61,] %>% filter(`Data stream/s` == "all" | grepl(input$stream, `Data stream/s`, ignore.case = T))
rhandsontable(tab, width = 1200) %>% hot_col(c(1:2,4:5), readOnly = TRUE) %>% hot_table(highlightRow = TRUE) %>%  hot_context_menu(allowRowEdit = FALSE, allowColEdit = FALSE) %>%
hot_cols(colWidths = c(200, 100, 200, 250, 400)) %>% hot_col("User input", renderer = col.hi.render)})
output$hot5 =  renderRHandsontable({
p_meta = values[["p_meta"]]
tab = p_meta[62:105,] %>% filter(`Data stream/s` == "all" | grepl(input$stream, `Data stream/s`, ignore.case = T))
rhandsontable(tab, width = 1200) %>% hot_col(c(1:2,4:5), readOnly = TRUE) %>% hot_table(highlightRow = TRUE) %>%  hot_context_menu(allowRowEdit = FALSE, allowColEdit = FALSE) %>%
hot_cols(colWidths = c(200, 100, 200, 250, 400)) %>% hot_col("User input", renderer = col.hi.render)})
####### Run BIO-MATE ##########
observeEvent(input$runBIOMATE, {
req(input$stream, input$upload)
process_meta = t(values$p_meta[,3])
colnames(process_meta) = values$p_meta[,1]
out_dir = file.path(values$file_path,"meta")
if(!file.exists(out_dir))
{dir.create(out_dir)}
write.csv(process_meta, file.path(out_dir, paste(input$stream, "_meta.csv", sep = "")))
if(input$stream == "PROF"){
BIOMATE::PROF_to_WHPE(outdir,file.path(local_out,"reformatted_data","BIO-SHARE" ))
}
if(input$stream == "PIG"){BIOMATE::PIG_to_WHPE(outdir,file.path(local_out,"reformatted_data","BIO-SHARE" ))}
})
# WHEN WRITING new data TO GITHUB
## add new source and method info to data
## add new citations to bib
## save processing metadata
## save reformatted files
####### Download Files ########
# output$download <- downloadHandler(
#   filename = function(){
#     paste0(input$text,".zip")
#
#   },
#   content = function(file){
#     #go to a temp dir to avoid permission issues
#     owd <- setwd(tempdir())
#     on.exit(setwd(owd))
#     files <- NULL;
#
#     #loop through the sheets
#     for (i in 1:input$sheet){
#       #write each sheet to a csv file, save the name
#       fileName <- paste(input$text,"_0",i,".csv",sep = "")
#       write.table(data()$wb[i],fileName,sep = ';', row.names = F, col.names = T)
#       files <- c(fileName,files)
#     }
#     #create the zip file
#     zip(file,files)
#   }
# )
}
# 3. call to shinyApp
shinyApp(ui, server)
View(source_info)
shinyApp(ui, server)
