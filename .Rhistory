# list variables that have info in the files
vars = colnames(info)[-c(1:which(colnames(info) == "start_data_var"))]
vars = vars[!unlist(lapply(info[,..vars], is.empty))]
# list variables where data is stored in file headers - if any
if(any(grepl("header-",info[,..vars]))){header_vars = vars[grepl("header-",info[,..vars])]
# variables
data_vars = vars[!grepl("header-",info[,..vars])]}else{data_vars = vars}
# information required to ID samples
ID_info = info[,..pig_id_data]
if(any(grepl("header-",ID_info))){
rm_head = colnames(ID_info)[!grepl("header-",ID_info)]
ID_info = ID_info[,..rm_head]}
# list all of the files in the data stream
files = list.files(path = info$path, pattern = info$extention,full.names = T,recursive = F)
if(length(files) == 0){stop(paste("file_path in UWY_meta.csv is wrong:",info$path,"It does not exist or the file is not here"))}
fl = files[1]
# text files - at the moment this is the only option. No netcdf files were found in search.
if(info$file_type == "text delim"){
# get the number of headers that are specified in the meta file to check that enough have been found in the file
names = data_vars[which(!unlist(lapply(info[,..data_vars],is.empty)))]
n_headers = length(which(colnames(info[,..names])[!duplicated(as.character(info[,..names]))] %in% all_headers))
# 2 data variables to one header variable - find less header matches
if(any(grepl("-",ID_info))){
n_headers = n_headers - length(which(grepl("-",ID_info)))
}
# get total number of lines in the file
f <- file( fl, open = "r" )
lines = readLines( f, -1L)
close(f)
n_lines = length(lines)
# read the file to get the header line.
# Identify the header by crosschecking the names recorded in the metadata information
f <- file( fl, open = "r" )
n = 0
while( TRUE ){
line <- readLines( f, 1L)
n = n+1
# if it is the end of the file?
if(n == n_lines){
if(exists("msg")){print(msg)}
print("Error: Couldnt find header line. Headers must be mislabled in metadata?")
break}
if(length(line)== 0){next}
# searching for data variables in headers
dv = data_vars[which(!unlist(lapply(info[,..data_vars],is.empty)))]
header_in_line = unlist(lapply(dv,function(x){grepl(info[,..x],line, fixed = T)}))
if(length(which(header_in_line == T) ) < n_headers & length(which(header_in_line == T) ) > 2){missing = dv[!header_in_line]
missing = missing[missing %in% pig_names[pig_names != "Notes"]]
msg = paste("Header assignments might not be right. Missing underway headers in",fl,"for",ex, "are:", paste(missing, collapse = ","))
}
# if there are at least three data_vars that apear, break this is likely the header line
if(length(which(header_in_line == T) ) >= n_headers  & !substr(line,1,1) %in% c("!","#")){
# write to a file to check header line is picked and variables have been grabbed. This can be removed. Maybe put a switch on for debugging.
tf = file(file.path(out_dir,paste("Check_headers",Sys.Date(),".txt", sep = "")),open = "at")
writeLines(paste(fl),tf)
writeLines(paste("The header line picked:",line),tf)
writeLines(paste("The variables found:",data_vars[which(header_in_line ==T)]),tf)
writeLines("All good?",tf)
writeLines(" ",tf)
close(tf)
header_line = line
break}
}
close( f )
# get number of the header line to skip for data table
n = grep(header_line,lines, fixed = T)
if(length(n) == 0){ n = 1}
# check for extra lines before the data table starts.
# There should be some numeric data in the table, but not in the header or unit lines.
b = n+1
line = fread(fl,stringsAsFactors = F, skip = n, nrows = 1, header = F)
while(!any(unlist(lapply(line,is.numeric)))){
line = fread(fl,stringsAsFactors = F, skip = b, nrows = 1, header = F)
b = b+1}
### Get data table ###
# Use fread to read the data table - this will adapt if there is a units line or not.
# catch the out-of-format lines here for debugging
#tryCatch({data = as.data.frame(fread(fl,stringsAsFactors = F, skip = n, na.strings = info$missing_value,strip.white = T , header = F))}, warning=function(w) print(fl))
# rectangular data shouldnt be read with fread
if(info$delim == "rect"){
data = read_table(fl,col_names = F, skip = b-1, na = info$missing_value,col_types = cols())
}else{
if(is.na(info$missing_value)){data = as.data.frame(fread(fl,stringsAsFactors = F, skip = b-1,strip.white = T, header = F, keepLeadingZeros = T))
if(any(grepl("POSIXct",sapply(data,class)))){
data = as.data.frame(fread(fl,stringsAsFactors = F, skip = b-1,strip.white = T, header = F, keepLeadingZeros = T, colClasses = list(character = grep("POSIXct",sapply(data,class)))))
}
}else{
data = as.data.frame(fread(fl,stringsAsFactors = F, skip = b-1, na.strings = as.character(info$missing_value),strip.white = T, header = F, keepLeadingZeros = T))
if(any(grepl("POSIXct",sapply(data,class)))){
data = as.data.frame(fread(fl,stringsAsFactors = F, skip = b-1, na.strings = as.character(info$missing_value),strip.white = T, header = F, keepLeadingZeros = T, colClasses = list(character = grep("POSIXct",sapply(data,class)))))
}
}
}
# get the header line
headers = as.character(fread(fl,stringsAsFactors = F, skip = n-1, nrows = 1, header = F))
headers = gsub("/fields=","",headers) # in seabass format
headers = headers[headers != "NA"]
colnames(data)[1:length(headers)] = headers
# remove empty columns
if(length(which(!is.na(data[,ncol(data)]))) == 0){data = data[,-ncol(data)]}
#data = data[rowSums(!is.na(data) | (data != "")) > 1,]
# # remove empty rows dont do this with underway data - data frames are too big!
# data = data[rowSums(matrix(unlist(lapply(as.matrix(data),is.empty)), ncol = ncol(data))) != ncol(data),]
# reassign missing value
for(cl in 1:ncol(data)){
data[which(data[,cl] == info$missing_value),cl] <- NA}
# get the variables listed in the metadata file and create a new reformatted data frame
grabbed_vars = info[,..data_vars]
idx = which(grabbed_vars %in% colnames(data))
grabbed_vars = grabbed_vars[,..idx]
colnames(grabbed_vars) = colnames(info[,..data_vars])[info[,..data_vars] %in% colnames(data)]
dataf = data.frame(data[,as.character(grabbed_vars)],stringsAsFactors = F)
colnames(dataf) = colnames(grabbed_vars)
# 2 data variables to one header variable
if(any(grepl("-",ID_info))){
for(gb in which(grepl("-",ID_info))){
ID_vars = unlist(strsplit(as.character(ID_info[,..gb]), "-"))
dataf[,colnames(ID_info[,..gb])] = apply(data[, ID_vars],1, paste, collapse = "")
}
}
### date must be entered in as year-month-day
if(grepl("-", info$DATE) & !grepl("header-", info$DATE)){
date_vars = unlist(strsplit(as.character(info$DATE), "-"))
dataf$DATE = sprintf("%04d-%02d-%02d", as.numeric(data[,date_vars[1]]), as.numeric(data[,date_vars[2]]), as.numeric(data[,date_vars[3]]))
info$DATE_format = "%Y-%m-%d"
}
### time must be hour-min or hour-min-sec
if(grepl("-", info$TIME) & !grepl("header-", info$TIME)){
time_vars = unlist(strsplit(as.character(info$TIME), "-"))
if(length(time_vars) == 3){
dataf$TIME = sprintf("%02d:%02d:%02d",as.numeric(data[,time_vars[1]]), as.numeric(data[,time_vars[2]]), as.numeric(data[,time_vars[3]]))
info$TIME_format = "%H:%M:%S"}
if(length(time_vars) == 2){
dataf$TIME = sprintf("%02d:%02d",as.numeric(data[,time_vars[1]]), as.numeric(data[,time_vars[2]]))
info$TIME_format = "%H:%M"}
}
f <- file( fl, open = "r" )
# read header lines and get stored data to add to the new reformatted data table
n2 = 0
while( TRUE ){ # stops when at the end of the header lines
n2 = n2+1
if(n2 > n){break}
line <- readLines( f, 1L )
if(length(line)== 0){next}
# get header data
if(exists("header_vars")){
# for each header variable store the associated data
for(hd in header_vars){
head_pattern = sub("header-","",info[,..hd])
if(grepl(head_pattern, line )){
dataf[,hd] = trimws(sub(info$header_sep,"",sub(head_pattern,"",line)))}
}
}
}
close( f )
# append data frame
if(fl == files[1]){
data_appended = dataf
}else{
data_appended = rbind(data_appended,dataf)
}
}
rm(data)
}
## header data ##
# loop through files to grab header data
for(fl in files){
# text files - at the moment this is the only option. No netcdf files were found in search.
if(info$file_type == "text delim"){
# get the number of headers that are specified in the meta file to check that enough have been found in the file
names = data_vars[which(!unlist(lapply(info[,..data_vars],is.empty)))]
n_headers = length(which(colnames(info[,..names])[!duplicated(as.character(info[,..names]))] %in% all_headers))
# 2 data variables to one header variable - find less header matches
if(any(grepl("-",ID_info))){
n_headers = n_headers - length(which(grepl("-",ID_info)))
}
# get total number of lines in the file
f <- file( fl, open = "r" )
lines = readLines( f, -1L)
close(f)
n_lines = length(lines)
# read the file to get the header line.
# Identify the header by crosschecking the names recorded in the metadata information
f <- file( fl, open = "r" )
n = 0
while( TRUE ){
line <- readLines( f, 1L)
n = n+1
# if it is the end of the file?
if(n == n_lines){
if(exists("msg")){print(msg)}
print("Error: Couldnt find header line. Headers must be mislabled in metadata?")
break}
if(length(line)== 0){next}
# searching for data variables in headers
dv = data_vars[which(!unlist(lapply(info[,..data_vars],is.empty)))]
header_in_line = unlist(lapply(dv,function(x){grepl(info[,..x],line, fixed = T)}))
if(length(which(header_in_line == T) ) < n_headers & length(which(header_in_line == T) ) > 2){missing = dv[!header_in_line]
missing = missing[missing %in% pig_names[pig_names != "Notes"]]
msg = paste("Header assignments might not be right. Missing underway headers in",fl,"for",ex, "are:", paste(missing, collapse = ","))
}
# if there are at least three data_vars that apear, break this is likely the header line
if(length(which(header_in_line == T) ) >= n_headers  & !substr(line,1,1) %in% c("!","#")){
# write to a file to check header line is picked and variables have been grabbed. This can be removed. Maybe put a switch on for debugging.
tf = file(file.path(out_dir,paste("Check_headers",Sys.Date(),".txt", sep = "")),open = "at")
writeLines(paste(fl),tf)
writeLines(paste("The header line picked:",line),tf)
writeLines(paste("The variables found:",data_vars[which(header_in_line ==T)]),tf)
writeLines("All good?",tf)
writeLines(" ",tf)
close(tf)
header_line = line
break}
}
close( f )
# get number of the header line to skip for data table
n = grep(header_line,lines, fixed = T)
if(length(n) == 0){ n = 1}
# check for extra lines before the data table starts.
# There should be some numeric data in the table, but not in the header or unit lines.
b = n+1
line = fread(fl,stringsAsFactors = F, skip = n, nrows = 1, header = F)
while(!any(unlist(lapply(line,is.numeric)))){
line = fread(fl,stringsAsFactors = F, skip = b, nrows = 1, header = F)
b = b+1}
### Get data table ###
# Use fread to read the data table - this will adapt if there is a units line or not.
# catch the out-of-format lines here for debugging
#tryCatch({data = as.data.frame(fread(fl,stringsAsFactors = F, skip = n, na.strings = info$missing_value,strip.white = T , header = F))}, warning=function(w) print(fl))
# rectangular data shouldnt be read with fread
if(info$delim == "rect"){
data = read_table(fl,col_names = F, skip = b-1, na = info$missing_value,col_types = cols())
}else{
if(is.na(info$missing_value)){data = as.data.frame(fread(fl,stringsAsFactors = F, skip = b-1,strip.white = T, header = F, keepLeadingZeros = T))
if(any(grepl("POSIXct",sapply(data,class)))){
data = as.data.frame(fread(fl,stringsAsFactors = F, skip = b-1,strip.white = T, header = F, keepLeadingZeros = T, colClasses = list(character = grep("POSIXct",sapply(data,class)))))
}
}else{
data = as.data.frame(fread(fl,stringsAsFactors = F, skip = b-1, na.strings = as.character(info$missing_value),strip.white = T, header = F, keepLeadingZeros = T))
if(any(grepl("POSIXct",sapply(data,class)))){
data = as.data.frame(fread(fl,stringsAsFactors = F, skip = b-1, na.strings = as.character(info$missing_value),strip.white = T, header = F, keepLeadingZeros = T, colClasses = list(character = grep("POSIXct",sapply(data,class)))))
}
}
}
# get the header line
headers = as.character(fread(fl,stringsAsFactors = F, skip = n-1, nrows = 1, header = F))
headers = gsub("/fields=","",headers) # in seabass format
headers = headers[headers != "NA"]
colnames(data)[1:length(headers)] = headers
# remove empty columns
if(length(which(!is.na(data[,ncol(data)]))) == 0){data = data[,-ncol(data)]}
#data = data[rowSums(!is.na(data) | (data != "")) > 1,]
# # remove empty rows dont do this with underway data - data frames are too big!
# data = data[rowSums(matrix(unlist(lapply(as.matrix(data),is.empty)), ncol = ncol(data))) != ncol(data),]
# reassign missing value
for(cl in 1:ncol(data)){
data[which(data[,cl] == info$missing_value),cl] <- NA}
# get the variables listed in the metadata file and create a new reformatted data frame
grabbed_vars = info[,..data_vars]
idx = which(grabbed_vars %in% colnames(data))
grabbed_vars = grabbed_vars[,..idx]
colnames(grabbed_vars) = colnames(info[,..data_vars])[info[,..data_vars] %in% colnames(data)]
dataf = data.frame(data[,as.character(grabbed_vars)],stringsAsFactors = F)
colnames(dataf) = colnames(grabbed_vars)
# 2 data variables to one header variable
if(any(grepl("-",ID_info))){
for(gb in which(grepl("-",ID_info))){
ID_vars = unlist(strsplit(as.character(ID_info[,..gb]), "-"))
dataf[,colnames(ID_info[,..gb])] = apply(data[, ID_vars],1, paste, collapse = "")
}
}
### date must be entered in as year-month-day
if(grepl("-", info$DATE) & !grepl("header-", info$DATE)){
date_vars = unlist(strsplit(as.character(info$DATE), "-"))
dataf$DATE = sprintf("%04d-%02d-%02d", as.numeric(data[,date_vars[1]]), as.numeric(data[,date_vars[2]]), as.numeric(data[,date_vars[3]]))
info$DATE_format = "%Y-%m-%d"
}
### time must be hour-min or hour-min-sec
if(grepl("-", info$TIME) & !grepl("header-", info$TIME)){
time_vars = unlist(strsplit(as.character(info$TIME), "-"))
if(length(time_vars) == 3){
dataf$TIME = sprintf("%02d:%02d:%02d",as.numeric(data[,time_vars[1]]), as.numeric(data[,time_vars[2]]), as.numeric(data[,time_vars[3]]))
info$TIME_format = "%H:%M:%S"}
if(length(time_vars) == 2){
dataf$TIME = sprintf("%02d:%02d",as.numeric(data[,time_vars[1]]), as.numeric(data[,time_vars[2]]))
info$TIME_format = "%H:%M"}
}
f <- file( fl, open = "r" )
# read header lines and get stored data to add to the new reformatted data table
n2 = 0
while( TRUE ){ # stops when at the end of the header lines
n2 = n2+1
if(n2 > n){break}
line <- readLines( f, 1L )
if(length(line)== 0){next}
# get header data
if(exists("header_vars")){
# for each header variable store the associated data
for(hd in header_vars){
head_pattern = sub("header-","",info[,..hd])
if(grepl(head_pattern, line )){
dataf[,hd] = trimws(sub(info$header_sep,"",sub(head_pattern,"",line)))}
}
}
}
close( f )
# append data frame
if(fl == files[1]){
data_appended = dataf
}else{
data_appended = rbind(data_appended,dataf)
}
}
rm(data)
}
# create a full data frame, with consistant organisation
data2 = data.frame(matrix(NA,nrow = nrow(data_appended),ncol = length(all_headers)))
colnames(data2) = all_headers
data2[,colnames(data_appended)] = data_appended
### reformat date and time
if(!is.empty(info$DATE) & !all(is.na(data2$DATE))){
if(nchar(data2$DATE[which(!is.empty(data2$DATE))[1]])>12 & grepl("AADC",info$source)){data2$DATE = substr(data2$DATE,1,12)}} #problems with old AADC data
if(info$DATE_format == "sec_since_year_start"){
Y = substr(ex,5,8)
if(!is.empty(info$DATE)){data2$DATE = as.POSIXct(paste(Y,"01","01", sep = "-"), tz = info$TZ) + as.numeric(data2$DATE)
}
if(!is.empty(info$TIME))
{data2$TIME = as.POSIXct(paste(Y,"01","01", sep = "-"), tz = info$TZ) + as.numeric(data2$TIME)
if(attributes(data2$TIME)$tzone != "UTC"){attributes(data2$TIME)$tzone = "UTC"}}
}else{
if(!is.empty(info$DATE) & !is.POSIXct(data2$DATE[1])){data2$DATE = as.Date(as.character(data2$DATE),format = info$DATE_format)
}
# times
if(info$DATE_format != info$TIME_format){
if(!is.empty(info$TIME))
{dt = paste(data2$DATE, data2$TIME)
data2$TIME = as.POSIXct(as.character(dt),format = paste("%Y-%m-%d",info$TIME_format),tz = info$TZ)
if(info$TIME_format == "%H"){data2$TIME = data2$TIME + as.numeric(data2$TIME)%%1}
if(attributes(data2$TIME)$tzone != "UTC"){attributes(data2$TIME)$tzone = "UTC"}
}
}else{
if(!is.empty(info$TIME)  )
{data2$TIME = as.POSIXct(as.character(data2$TIME),format = info$TIME_format,tz = info$TZ)
if(attributes(data2$TIME)$tzone != "UTC"){attributes(data2$TIME)$tzone = "UTC"}}
}}
library(lubridate)
if(info$DATE_format == "sec_since_year_start"){
Y = substr(ex,5,8)
if(!is.empty(info$DATE)){data2$DATE = as.POSIXct(paste(Y,"01","01", sep = "-"), tz = info$TZ) + as.numeric(data2$DATE)
}
if(!is.empty(info$TIME))
{data2$TIME = as.POSIXct(paste(Y,"01","01", sep = "-"), tz = info$TZ) + as.numeric(data2$TIME)
if(attributes(data2$TIME)$tzone != "UTC"){attributes(data2$TIME)$tzone = "UTC"}}
}else{
if(!is.empty(info$DATE) & !is.POSIXct(data2$DATE[1])){data2$DATE = as.Date(as.character(data2$DATE),format = info$DATE_format)
}
# times
if(info$DATE_format != info$TIME_format){
if(!is.empty(info$TIME))
{dt = paste(data2$DATE, data2$TIME)
data2$TIME = as.POSIXct(as.character(dt),format = paste("%Y-%m-%d",info$TIME_format),tz = info$TZ)
if(info$TIME_format == "%H"){data2$TIME = data2$TIME + as.numeric(data2$TIME)%%1}
if(attributes(data2$TIME)$tzone != "UTC"){attributes(data2$TIME)$tzone = "UTC"}
}
}else{
if(!is.empty(info$TIME)  )
{data2$TIME = as.POSIXct(as.character(data2$TIME),format = info$TIME_format,tz = info$TZ)
if(attributes(data2$TIME)$tzone != "UTC"){attributes(data2$TIME)$tzone = "UTC"}}
}}
if(!is.empty(info$TIME)){
for(dr in 1:nrow(data2)){
data2$TIME2[dr] = sub(as.character(as.Date(data2$TIME[dr])),"",print.POSIXct2(data2$TIME[dr]))
data2$TIME2[dr] = trimws(sub("UTC","",data2$TIME2[dr]))
}
data2$TIME = data2$TIME2
data2 = data2[,-which(colnames(data2) == "TIME2")]
}
# this small function prevents the drop of midnight 00:00:00
print.POSIXct2 <- function(x){format(x,"%Y-%m-%d %H:%M:%S %Z")}
if(!is.empty(info$TIME)){
for(dr in 1:nrow(data2)){
data2$TIME2[dr] = sub(as.character(as.Date(data2$TIME[dr])),"",print.POSIXct2(data2$TIME[dr]))
data2$TIME2[dr] = trimws(sub("UTC","",data2$TIME2[dr]))
}
data2$TIME = data2$TIME2
data2 = data2[,-which(colnames(data2) == "TIME2")]
}
info$LATITUDE
info$LONGITUDE
info$LATITUDE == info$LONGITUDE & !is.empty(info$LATITUDE)
### reformat position ###
# positions
if(info$LATITUDE == info$LONGITUDE & !is.empty(info$LATITUDE)){
lat_lon = strsplit(data2$LATITUDE, split = " ")
data2$LATITUDE = lat_lon[[1]][1]
data2$LONGITUDE = lat_lon[[1]][2]
}
# if not in %deg
# %deg %min %sec %pos format or %deg %min %pos format
if(grepl("%pos",info$POSITION_format) & grepl("%min",info$POSITION_format)){
# grab the delimiter
delim = substr(sub("%pos","",sub("%deg","",sub("%min","",sub("%sec","",info$POSITION_format)))),1,1)
### start pos
# split based on delimiter
lat = gsub("[[:alpha:]]","",data2$LATITUDE)
lat = strsplit(lat,split = delim)
lon = gsub("[[:alpha:]]","",data2$LONGITUDE)
lon = strsplit(lon,split = delim)
# turn to numeric
if(length(lat[[1]]) == 2){
lat = as.numeric(lat[[1]][1]) + as.numeric(lat[[1]][2])/60
lon = as.numeric(lon[[1]][1]) + as.numeric(lon[[1]][2])/60
}
if(length(lat[[1]]) == 3){
lat = as.numeric(lat[[1]][1]) + as.numeric(lat[[1]][2])/60 + as.numeric(lat[[1]][3])/(60*60)
lon = as.numeric(lon[[1]][1]) + as.numeric(lon[[1]][2])/60 + as.numeric(lon[[1]][3])/(60*60)
}
# turn to negative based on %pos
data2$LATITUDE = as.numeric(lat)
data2$LONGITUDE = as.numeric(lon)
if(gsub("[^[:alpha:]]+","", data2$LATITUDE) == "S"){data2$LATITDUE = -as.numeric(lat)}
if(gsub("[^[:alpha:]]+","", data2$LONGITUDE) == "W"){data2$LONGITUDE = -as.numeric(lon)}
}
if(info$POSITION_format != "%deg" & grepl("%deg",info$POSITION_format) & length(strsplit(info$POSITION_format,split = "%")[[1]]) == 2 ){
for(dr in 1:nrow(data2)){
data2$LATITUDE[dr] = sub(paste("\\",sub("%deg","",info$POSITION_format),sep = ""),"" ,data2$LATITUDE[dr])
data2$LONGITUDE[dr] = sub(paste("\\",sub("%deg","",info$POSITION_format),sep = ""),"" ,data2$LONGITUDE[dr])}
}
data2$LATITUDE = as.numeric(data2$LATITUDE)
data2$LONGITUDE = as.numeric(data2$LONGITUDE)
#### Write the new file
# new file name and path
if(duplicate){new_file = paste(paste(ex,"UWY",sep = "_"),".csv",sep = "")}else{
new_file = paste(paste(ex,"UWY",sep = "_"),".csv",sep = "")}
#### Write the new file
# new file name and path
new_file = paste(paste(ex,"UWY",sep = "_"),".csv",sep = "")
new_file_path = file.path(out_dir,new_file)
# if the file exists, delete it
if(file.exists(new_file_path)){unlink(new_file_path)}
# if(exists("sub_meta")){
#   files = list()
#     for(sb in 1:nrow(sub_meta)){
#     files = c(files, list.files(path = sub_meta[sb,]$path, pattern = sub_meta[sb,]$extention,full.names = T,recursive = F))}
#   files = unlist(files)
#   }else{
# files = list.files(path = info$path, pattern = info$extention,full.names = T,recursive = F)}
subsource = source_info %>% filter(source == info$source)
cite_tags = c(unlist(strsplit(info$citation,";" )), unlist(strsplit(subsource$citations,";" )))
cite_tags = cite_tags[is.character(cite_tags)]
info$citation
View(data2)
# Title: create_package_data.R
# Author: K. Baldry - IMAS/UTAS
# Created: 17/07/2021
#
# This script updates BIO-MATE.
#
#
#
library(bibtex)
library(roxygen2)
# update_package <- function(){}
### EXPOCODE tables
countries = fread("../Rpackage/inst/codes/NODC_countrylist.csv")
platforms = fread("../Rpackage/inst/codes/WOD_s_3_platform.csv")
platforms$`Platform Name` = unlist(lapply(platforms$`Platform Name` , function(x){strsplit(x, split = "\\(")[[1]][1]}))
# add missing codes
platforms[nrow(platforms)+1,] = c("11259","RUB3","AKADEMIK TRYOSHNIKOV")
platforms[nrow(platforms)+1,] = c("10005","35XI","Tara")
### Citation .bib file
# citation files are updated within bibpath
# compile new citations into one file
bibpath = "./product_data/supporting_information/citations"
path_to_bib_files = list.files(bibpath, pattern = "*.bib")
combined_bib <- ""
for (path_to_bib_file in path_to_bib_files) {
fileCon <- file(file.path(bibpath,path_to_bib_file))
content <- readLines(fileCon)
close(fileCon)
combined_bib <- paste0(combined_bib, "\n", "\n", trimws(paste0(content, collapse="\n")))
}
cat(combined_bib, file=file.path("../Rpackage/inst/citations","BIO-MATE_references.bib"), "\n")
# create bib object and save in R package
bib = read.bib(file.path("../Rpackage/inst/citations","BIO-MATE_references.bib"))
### Source information
source_info = read.csv("./product_data/supporting_information/BIOMATE_SOURCES.txt", stringsAsFactors = F)
### Method information
method_info = read.csv("./product_data/supporting_information/BIOMATE_Methods.txt", stringsAsFactors = F)
# compile processing metadata - only do once
# library(data.table)
# library(BIOMATE)
# path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
#
# for(c in c("regression_test", "C1", "C2", "C3", "C4", "C5")){
#   meta = fread(file.path(path,"BIO-MATE","product_data","processing_metadata",c,"PIG_meta.csv"),header = T,strip.white = T,stringsAsFactors = F)
#   if(c != "regression_test"){
#     META = rbind(META,meta)}else{META = meta}
# }
# META = META[rowSums(matrix(unlist(lapply(as.matrix(META),is.empty)), ncol = ncol(META))) != ncol(META),]
#
# # Methods look-up table
# Mdf = unique((META[,c("analysis_type","Method")]))
# Mdf = Mdf[order(Mdf$analysis_type),]
# write.csv(Mdf, file=file.path("./product_data/supporting_information","BIOMATE_METHODS.txt"),row.names = F)
### save data
save(bib,source_info,method_info,platforms, countries,file =file.path("../Rpackage/data","BIOMATE.rda"))
### Compile package
roxygen2::roxygenise("../Rpackage")
roxygen2::roxygenise("../Rpackage")
roxygen2::roxygenise("../Rpackage")
roxygen2::roxygenise("../Rpackage")
