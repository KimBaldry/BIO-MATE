ref_idx = grep("@", lines)
stream_idx = unlist(lapply(stream, function(x){grep(x,lines[ref_idx], ignore.case = T)}))
stream_idx = unlist(lapply("ctd", function(x){grep(x,lines[ref_idx], ignore.case = T)}))
ctd_idx = unlist(lapply("ctd", function(x){grep(x,lines[ref_idx], ignore.case = T)}))
if(length(ctd_idx) > 0){
for(j in ctd_idx){
lines[ref_idx[j]] = str_replace(lines[ref_idx[j]], "_ctd", "_prof")
}
}
# change all _ctd to _prof in references
# direct to citation files
library(stringr)
if(length(ctd_idx) > 0){
for(j in ctd_idx){
lines[ref_idx[j]] = str_replace(lines[ref_idx[j]], "_ctd", "_prof")
}
}
lines
lines <- readLines(file.path(meta_path,i))
lines
# Overwrite the file
file.remove(i)
# Overwrite the file
file.remove(file.path(meta_path, i))
# Overwrite the file
OutName = file.path(meta_path, i)
file.remove(OutName)
outFile <- file(OutName, "w")
writeLines(lines, outFile)
close(outFile)
OutName
lines
lines <- readLines(file.path(meta_path,i))
ref_idx = grep("@", lines)
ctd_idx = unlist(lapply("ctd", function(x){grep(x,lines[ref_idx], ignore.case = T)}))
if(length(ctd_idx) > 0){
for(j in ctd_idx){
lines[ref_idx[j]] = str_replace(lines[ref_idx[j]], "_ctd", "_prof")
}
}
lines
ref_idx[j]
lines[ref_idx[j]]
lines
length(ctd_idx) > 0
# Overwrite the file
OutName = file.path(meta_path, i)
file.remove(OutName)
outFile <- file(OutName, "w")
writeLines(lines, outFile)
close(outFile)
# change all _ctd to _prof in references
# direct to citation files
library(stringr)
meta_path = "./Rpackage/data/citations"
file_names = list.files(meta_path)
for(i in file_names){
lines <- readLines(file.path(meta_path,i))
ref_idx = grep("@", lines)
ctd_idx = unlist(lapply("ctd", function(x){grep(x,lines[ref_idx], ignore.case = T)}))
if(length(ctd_idx) > 0){
for(j in ctd_idx){
lines[ref_idx[j]] = str_replace(lines[ref_idx[j]], "_ctd", "_prof")
}
}
# Overwrite the file
OutName = file.path(meta_path, i)
file.remove(OutName)
outFile <- file(OutName, "w")
writeLines(lines, outFile)
close(outFile)
}
warnings()
library(dplyr)
library(tools)
library(data.table)
library(ncdf4)
library(readr)
library(geosphere)
library(stringi)
library(tidyr)
source(file.path("./src","Marlin_SS_split_CTD.R"))
source(file.path("./src","split_compiled_delim_file.R"))
files = c("MNF_FR199710_ctd_trawler.csv",
"O&A_SS199603_ctd_trawler.csv",
"MNF_IN2016_V01_ctd_trawler.csv",
"MNF_IN2016_V02_ctd_trawler.csv",
"MNF_IN2016_V03_ctd_trawler.csv",
"MNF_IN2018_V01_ctd_trawler.csv")
expos = c("09FA19971125",
"09SS19960513",
"096U20160107",
"096U20160314",
"096U20160426",
"096U20180110"
)
for(ex in 1:length(expos)){
split_compiled_delim_file(path = file.path("E:/Data_downloads/Marlin",expos[ex]), file_name = files[ex], delim = ",",expo_split = F,station_split = T, station_var_name = "STATION")
}
library(tidync)
tidync("E:/Data_downloads/SISMER/35MF20040103/ctd")
tidync("E:/Data_downloads/SISMER/35MF20040103/ctd/2004_4200010.nc")
library(netcdf4)
library(ncdf4)
f1 = nc_open("E:/Data_downloads/SISMER/35MF20040103/ctd/2004_4200010.nc")
f1
ncvar_get(f1, "SDN_STATION")
ncvar_get(f1, "TIME")
A = ncvar_get(f1, "TIME")
help(julian)
julian(a, origin = as.date(-4713-01-01))
julian(AQ, origin = as.date(-4713-01-01))
julian(A, origin = as.date(-4713-01-01))
julian(A[1], origin = as.date(-4713-01-01))
julian(2452014, origin = as.date(-4713-01-01))
julian('2452014', origin = as.date(-4713-01-01))
julian2date(2452014, origin = as.date(-4713-01-01))
month.day.year(2452014, origin = as.date(-4713-01-01))
library(chron)
month.day.year(2452014, origin = as.date(-4713-01-01))
month.day.year(2452014, origin = as.Date(-4713-01-01))
month.day.year(2452014, origin = "-4713-01-01")
month.day.year(2452014)
month.day.year(2452014, origin = "0-01-01")
month.day.year(2452014, origin = "1970-01-01")
month.day.year(2452014, origin = c(1,1,-4713))
A
names(f1$var)
ncvar_get(f1, "TIME")
data = read.table(file = "E:/Data_downloads/SISMER/35MF19940126/ctd/1994_94200020.txt", header = T, sep = delim, stringsAsFactors = F, strip.white = T,fill = T)
data = read.table(file = "E:/Data_downloads/SISMER/35MF19940126/ctd/1994_94200020.txt", header = T, sep = "/t", stringsAsFactors = F, strip.white = T,fill = T)
data = read.table(file = "E:/Data_downloads/SISMER/35MF19940126/ctd/1994_94200020.txt", header = T, sep = "\t", stringsAsFactors = F, strip.white = T,fill = T)
fl = "E:/Data_downloads/SISMER/35MF19940126/ctd/1994_94200020.txt"
f <- file( fl, open = "r" )
n = 0
while( TRUE ){
line <- readLines( f, 1L )
n = n+1
if(is.empty(line)){next}
if(line[1] != "/"){break}
}
line[1]
substr(line, 1,2)
substr(line,1,2) != "//"
library(dplyr)
library(tools)
library(data.table)
library(ncdf4)
library(readr)
library(geosphere)
library(stringi)
library(tidyr)
library(devtools)
devtools::install_github("KimBaldry/BIO-MATE", subdir = "Rpackage")
f <- file( fl, open = "r" )
n = 0
while( TRUE ){
line <- readLines( f, 1L )
n = n+1
if(is.empty(line)){next}
if(substr(line,1,2) != "//"){break}
}
BIOMATE::is.empty(line)
f <- file( fl, open = "r" )
close(f)
f <- file( fl, open = "r" )
n = 0
while( TRUE ){
line <- readLines( f, 1L )
n = n+1
if(BIOMATE::is.empty(line)){next}
if(substr(line,1,2) != "//"){break}
}
n
close(f)
data = read.table(file = fl, header = T, sep = "\t", stringsAsFactors = F, strip.white = T,fill = T, skip = n-1)
data$Longitude..degrees_east.[1]
colnames(data)[4,5,6] = c("TIME","LATITUDE", "LONGITUDE")
colnames(data)[c(4,5,6)] = c("TIME","LATITUDE", "LONGITUDE")
colnames(data)[c(4,5,6,10,12,14,16,18)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL", "DOXY")
colnames(data)[c(4,5,6,10,12,14,16)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL", "DOXY")
fl
ex = "35MF19950927"
path = paste("E:/Data_downloads/SISMER", ex, "ctd", sep = "/")
fl = list.files(path, pattern = "*.txt")
f <- file( fl, open = "r" )
fl
path
fl = list.files(path, pattern = "*.txt")
f <- file( fl, open = "r" )
n = 0
fl
fl = file.path(path,list.files(path, pattern = "*.txt"))
f <- file( fl, open = "r" )
n = 0
while( TRUE ){
line <- readLines( f, 1L )
n = n+1
if(BIOMATE::is.empty(line)){next}
if(substr(line,1,2) != "//"){break}
}
close(f)
ex = "35MF19980121"
path = paste("E:/Data_downloads/SISMER", ex, "ctd", sep = "/")
fl = file.path(path,list.files(path, pattern = "*.txt"))
f <- file( fl, open = "r" )
n = 0
while( TRUE ){
line <- readLines( f, 1L )
n = n+1
if(BIOMATE::is.empty(line)){next}
if(substr(line,1,2) != "//"){break}
}
close(f)
data = read.table(file = fl, header = T, sep = "\t", stringsAsFactors = F, strip.white = T,fill = T, skip = n-1)
colnames(data)[c(4,5,6,10,14,16)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL")}
colnames(data)[c(4,5,6,10,14,16)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL")
ex = "35MF19950927"
path = paste("E:/Data_downloads/SISMER", ex, "ctd", sep = "/")
fl = file.path(path,list.files(path, pattern = "*.txt"))
f <- file( fl, open = "r" )
n = 0
while( TRUE ){
line <- readLines( f, 1L )
n = n+1
if(BIOMATE::is.empty(line)){next}
if(substr(line,1,2) != "//"){break}
}
close(f)
data = read.table(file = fl, header = T, sep = "\t", stringsAsFactors = F, strip.white = T,fill = T, skip = n-1)
ex = "35MF20040103"
path = paste("E:/Data_downloads/SISMER", ex, "ctd", sep = "/")
fl = file.path(path,list.files(path, pattern = "*.txt"))
n = 0
while( TRUE ){
line <- readLines( f, 1L )
n = n+1
if(BIOMATE::is.empty(line)){next}
if(substr(line,1,2) != "//"){break}
}
fl
close(f)
fl = file.path(path,list.files(path, pattern = "*.txt"))
f <- file( fl, open = "r" )
n = 0
while( TRUE ){
line <- readLines( f, 1L )
n = n+1
if(BIOMATE::is.empty(line)){next}
if(substr(line,1,2) != "//"){break}
}
close(f)
data = read.table(file = fl, header = T, sep = "\t", stringsAsFactors = F, strip.white = T,fill = T, skip = n-1)
colnames(data)[c(4,5,6,10,14,16,18)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL","FLUOR"
)
# split according to finite station type
idx = is.finite(data$Station)
# split according to finite station type
idx = which(is.finite(data$Station))
st = 1
sub_data = data[idx[st]:(idx[st+1]-1),]
View(sub_data)
# fill in missing values
sub_data[,c("Cruise","Station", "TIME", "LATITUDE", "LONGITUDE")] = sub_data[1,c("Cruise","Station", "TIME", "LATITUDE", "LONGITUDE")]
View(sub_data)
expos = c("35MF19940126", "35MF19950927", "35MF19980121", "35MF20040103")
for(ex in expos){
path = paste("E:/Data_downloads/SISMER", ex, "ctd", sep = "/")
fname = list.files(path, pattern = "*.txt")
fl = file.path(path,fname)
f <- file( fl, open = "r" )
n = 0
while( TRUE ){
line <- readLines( f, 1L )
n = n+1
if(BIOMATE::is.empty(line)){next}
if(substr(line,1,2) != "//"){break}
}
close(f)
data = read.table(file = fl, header = T, sep = "\t", stringsAsFactors = F, strip.white = T,fill = T, skip = n-1)
# change header names
if(ex == "35MF19940126" | ex == "35MF19950927"){
colnames(data)[c(4,5,6,10,12,14,16)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL", "DOXY")}
if(ex == "35MF19980121"){colnames(data)[c(4,5,6,10,14,16)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL")}
if(ex == "35MF20040103"){colnames(data)[c(4,5,6,10,14,16,18)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL","FLUOR")}
# split according to finite station type
idx = which(is.finite(data$Station))
for(st in 1:length(idx)){
sub_data = data[idx[st]:(idx[st+1]-1),]
# fill in missing values
sub_data[,c("Cruise","Station", "TIME", "LATITUDE", "LONGITUDE")] = sub_data[1,c("Cruise","Station", "TIME", "LATITUDE", "LONGITUDE")]
# save file in new split directory
write.csv( file.path(paste("E:/Data_downloads/SISMER", ex, "ctd","split", sep = "/"), paste(fname,"_", sub_data$Station[1],".csv", sep = "")), row.names = F )
}
}
file.path(paste("E:/Data_downloads/SISMER", ex, "ctd","split", sep = "/"), paste(fname,"_", sub_data$Station[1],".csv", sep = ""))
View(sub_data)
# save file in new split directory
write.csv( file.path(paste("E:/Data_downloads/SISMER", ex, "ctd","split", sep = "/"), paste(ex,"ctd_", sub_data$Station[1],".csv", sep = "")), row.names = F )
expos = c("35MF19940126", "35MF19950927", "35MF19980121", "35MF20040103")
for(ex in expos){
path = paste("E:/Data_downloads/SISMER", ex, "ctd", sep = "/")
fname = list.files(path, pattern = "*.txt")
fl = file.path(path,fname)
f <- file( fl, open = "r" )
n = 0
while( TRUE ){
line <- readLines( f, 1L )
n = n+1
if(BIOMATE::is.empty(line)){next}
if(substr(line,1,2) != "//"){break}
}
close(f)
data = read.table(file = fl, header = T, sep = "\t", stringsAsFactors = F, strip.white = T,fill = T, skip = n-1)
# change header names
if(ex == "35MF19940126" | ex == "35MF19950927"){
colnames(data)[c(4,5,6,10,12,14,16)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL", "DOXY")}
if(ex == "35MF19980121"){colnames(data)[c(4,5,6,10,14,16)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL")}
if(ex == "35MF20040103"){colnames(data)[c(4,5,6,10,14,16,18)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL","FLUOR")}
# split according to finite station type
idx = which(is.finite(data$Station))
for(st in 1:length(idx)){
sub_data = data[idx[st]:(idx[st+1]-1),]
# fill in missing values
sub_data[,c("Cruise","Station", "TIME", "LATITUDE", "LONGITUDE")] = sub_data[1,c("Cruise","Station", "TIME", "LATITUDE", "LONGITUDE")]
# save file in new split directory
write.csv(sub_data, file.path(paste("E:/Data_downloads/SISMER", ex, "ctd","split", sep = "/"), paste(ex,"ctd_", sub_data$Station[1],".csv", sep = "")), row.names = F )
}
}
expos = c("35MF19940126", "35MF19950927", "35MF19980121", "35MF20040103")
for(ex in expos){
path = paste("E:/Data_downloads/SISMER", ex, "ctd", sep = "/")
fname = list.files(path, pattern = "*.txt")
fl = file.path(path,fname)
f <- file( fl, open = "r" )
n = 0
while( TRUE ){
line <- readLines( f, 1L )
n = n+1
if(BIOMATE::is.empty(line)){next}
if(substr(line,1,2) != "//"){break}
}
close(f)
data = read.table(file = fl, header = T, sep = "\t", stringsAsFactors = F, strip.white = T,fill = T, skip = n-1)
# change header names
if(ex == "35MF19940126" | ex == "35MF19950927"){
colnames(data)[c(4,5,6,10,12,14,16)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL", "DOXY")}
if(ex == "35MF19980121"){colnames(data)[c(4,5,6,10,14,16)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL")}
if(ex == "35MF20040103"){colnames(data)[c(4,5,6,10,14,16,18)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL","FLUOR")}
# split according to finite station type
idx = which(is.finite(data$Station))
for(st in 1:length(idx)){
sub_data = data[idx[st]:(idx[st+1]-1),]
# fill in missing values
sub_data[,c("Cruise","Station", "TIME", "LATITUDE", "LONGITUDE")] = sub_data[1,c("Cruise","Station", "TIME", "LATITUDE", "LONGITUDE")]
# save file in new split directory
write.csv(sub_data, file.path(paste("E:/Data_downloads/SISMER", ex, "ctd","split", sep = "/"), paste(ex,"ctd_", sub_data$Station[1],".csv", sep = "")), row.names = F )
}
}
expos = c("35MF19940126", "35MF19950927", "35MF19980121", "35MF20040103")
for(ex in expos){
path = paste("E:/Data_downloads/SISMER", ex, "ctd", sep = "/")
fname = list.files(path, pattern = "*.txt")
fl = file.path(path,fname)
f <- file( fl, open = "r" )
n = 0
while( TRUE ){
line <- readLines( f, 1L )
n = n+1
if(BIOMATE::is.empty(line)){next}
if(substr(line,1,2) != "//"){break}
}
close(f)
data = read.table(file = fl, header = T, sep = "\t", stringsAsFactors = F, strip.white = T,fill = T, skip = n-1)
# change header names
if(ex == "35MF19940126" | ex == "35MF19950927"){
colnames(data)[c(4,5,6,10,12,14,16)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL", "DOXY")}
if(ex == "35MF19980121"){colnames(data)[c(4,5,6,10,14,16)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL")}
if(ex == "35MF20040103"){colnames(data)[c(4,5,6,10,14,16,18)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL","FLUOR")}
# split according to finite station type
idx = which(is.finite(data$Station))
for(st in 1:length(idx)){
if(st = length(idx)){sub_data = data[idx[st]:length(data),]}else{sub_data = data[idx[st]:(idx[st+1]-1),]}
expos = c("35MF19940126", "35MF19950927", "35MF19980121", "35MF20040103")
for(ex in expos){
path = paste("E:/Data_downloads/SISMER", ex, "ctd", sep = "/")
fname = list.files(path, pattern = "*.txt")
fl = file.path(path,fname)
f <- file( fl, open = "r" )
n = 0
while( TRUE ){
line <- readLines( f, 1L )
n = n+1
if(BIOMATE::is.empty(line)){next}
if(substr(line,1,2) != "//"){break}
}
close(f)
data = read.table(file = fl, header = T, sep = "\t", stringsAsFactors = F, strip.white = T,fill = T, skip = n-1)
# change header names
if(ex == "35MF19940126" | ex == "35MF19950927"){
colnames(data)[c(4,5,6,10,12,14,16)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL", "DOXY")}
if(ex == "35MF19980121"){colnames(data)[c(4,5,6,10,14,16)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL")}
if(ex == "35MF20040103"){colnames(data)[c(4,5,6,10,14,16,18)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL","FLUOR")}
# split according to finite station type
idx = which(is.finite(data$Station))
for(st in 1:length(idx)){
if(st == length(idx)){sub_data = data[idx[st]:length(data),]}else{sub_data = data[idx[st]:(idx[st+1]-1),]}
# fill in missing values
sub_data[,c("Cruise","Station", "TIME", "LATITUDE", "LONGITUDE")] = sub_data[1,c("Cruise","Station", "TIME", "LATITUDE", "LONGITUDE")]
# save file in new split directory
write.csv(sub_data, file.path(paste("E:/Data_downloads/SISMER", ex, "ctd","split", sep = "/"), paste(ex,"ctd_", sub_data$Station[1],".csv", sep = "")), row.names = F )
}
}
f1 = nc_open('E:/Data_downloads/SISMER/35MF19940126/ctd/1994_94200020.nc')
print(f1)
nc_close(f1)
f1 = nc_open('E:/Data_downloads/SISMER/35MF19980121/ctd/1998_98200090.nc')
print(f1)
close(f1)
nc_close(f1)
f1 = nc_open('E:/Data_downloads/SISMER/35MF20040103/ctd/2004_4200010.nc')
prit(f1)
print(f1)
nc_close(f1)
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C5"),userID = "IMASUTASKB", row_start = 14)
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
BIOMATE::PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C5"),userID = "IMASUTASKB", row_start = 14)
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
BIOMATE::PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C5"),userID = "IMASUTASKB")
traceback()
packageVersion("data.table"
)
install.packages(data.table)
install.packages("data.table")
install.packages("data.table")
library(data.table)
packageVersion("data.table"
)
install.packages("data.table")
library(data.table)
packageVersion("data.table")
library(dplyr)
library(tools)
library(data.table)
library(ncdf4)
library(readr)
library(geosphere)
library(stringi)
library(tidyr)
library(devtools)
devtools::install_github("KimBaldry/BIO-MATE", subdir = "Rpackage")
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
BIOMATE::PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C5"),userID = "IMASUTASKB")
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","BIO-MATE","processing_metadata","regression_test"),userID = "IMASUTASKB")
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
BIOMATE::PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","BIO-MATE","processing_metadata","regression_test"),userID = "IMASUTASKB")
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
BIOMATE::PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","processing_metadata","regression_test"),userID = "IMASUTASKB")
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
BIOMATE::PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","regression_test"),userID = "IMASUTASKB")
packageVersion("data.frame")
PROF_to_WHPE = function(file_path, path_out,
userID = "IMASUTASKB"
row_start = 1
row_end = NA
trace_file = F
row_start = 1
userID = "IMASUTASKB"
file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C5")
path_out = file.path(path,"reformatted_data")
# this small function prevents the drop of midnight 00:00:00
print.POSIXct2 <- function(x){format(x,"%Y-%m-%d %H:%M:%S %Z")}
### Output directory
# if the output directory does not exist for this layer, create it
out_dir = file.path(path_out,"profiling_sensors")
if(!file.exists(out_dir))
{dir.create(out_dir)}
# headers that are in the metadata file
out_header_data = c("STNNBR",	"CASTNO", "DATE","TIME_s",	"TIME_b",	"TIME_e",	"LATITUDE_s",	"LONGITUDE_s",	"LATITUDE_b",	"LONGITUDE_b",	"LATITUDE_e",	"LONGITUDE_e")
### read in metadata file
# check that the file exists
meta_path = file.path(file_path,"PROF_meta.csv")
if(!file.exists(meta_path)){stop(paste("Error: There is no file named PROF_meta.csv located in the dirctory",file_path))}
# read it in
meta = fread(file = meta_path,header = T,strip.white = T,stringsAsFactors = F, keepLeadingZeros = T)
heads = as.character(fread(meta_path, nrows = 1, header = F, stringsAsFactors = F))
heads = heads[heads != "NA"]
heads
meta = meta[,..heads]
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
BIOMATE::PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C5"),userID = "IMASUTASKB")
traceback()
devtools::install_github("KimBaldry/BIO-MATE", subdir = "Rpackage")
devtools::install_github("KimBaldry/BIO-MATE", subdir = "Rpackage", force = T)
library(BIOMATE)
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/BIO-MATE"
PROF_to_WHPE(path_out = file.path(path,"regression_test","reformatted_data"), file_path = file.path(path,"BIO-MATE","processing_metadata","regression_test"),userID = "IMASUTASKB")
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/BIO-MATE"
PROF_to_WHPE(path_out = file.path(path,"regression_test","reformatted_data"), file_path = file.path(path,"processing_metadata","regression_test"),userID = "IMASUTASKB")
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/BIO-MATE"
PROF_to_WHPE(path_out = file.path(path,"regression_test","reformatted_data"), file_path = file.path(path,"package_data","processing_metadata","regression_test"),userID = "IMASUTASKB")
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/BIO-MATE"
PROF_to_WHPE(path_out = file.path(path,"regression_test","reformatted_data"), file_path = file.path(path,"product_data","processing_metadata","regression_test"),userID = "IMASUTASKB")
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
BIOMATE::PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C5"),userID = "IMASUTASKB")
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
BIOMATE::PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C5"),userID = "IMASUTASKB")
traceback()
is.null(-999) || is.character(-999)
devtools::install_github("KimBaldry/BIO-MATE", subdir = "Rpackage")
