*** look for a second MLD
separate plots based on stab. plot chl

  library(data.table)
  library(seacarb)
  library(oce)
  library(birk)
  library(dplyr)
  path = "C:/Users/kabaldry/Documents/PhD/Introduction_review/SRC"
  source(file.path(path,"front_class_sorarc.R"))
  source(file.path(path,"front_Charrassin2008.R"))
  source(file.path(path,"front_class_Sokolov2009_theta.R"))
  source(file.path(path,"front_class.R"))
  # This figure explores how water column structure relates to the distribution of chlorophyll
  # expo_path = "C:/Users/kabaldry/Documents/PhD/Introduction_review/Data"
  # data_path = "D:/Data_Aggregation"
  pigment_path = "E:/Data_Aggregation_layers/pigments"
  
  pig_data = read.csv(file.path(pigment_path,"PIG_data_layer.csv"), stringsAsFactors = F)
  pig_data = pig_data %>% dplyr::filter(CTD_match == 1)
  #select those for which CTD data is 
  pig_data = pig_data %>% mutate(CTD_ID = paste(EXPOCODE,"CTD",STNNBR,CASTNO, sep = "_"))
  CTD_IDs = unique(pig_data$CTD_ID)
  
  
  idx = 0
  prof_data = data.frame("CTD_ID" = character(), "LAT" = numeric(), "LON" = numeric(), "DATE" = as.character(), "TIME" = character(), "TIME_QF" = character(), "YYYY" = numeric(),
                         "MM" = numeric(), "DD" = numeric(),"nobs" = numeric(), "min_d" = numeric(), 
                         "max_d" = numeric(), "CTD_max_d" = numeric(), "CTD_min_d" = numeric(), "MLD" = numeric(), "QI_MLD" = numeric(), "TLD" = numeric(), "QI_TLD" = numeric(), "FWL" = character(),
                         "in_Analysis" = character(),
                         "SCM" = character(), "SCM_d" = numeric(), "SCM_val" = numeric(), "surf_val" = numeric(),
                          "nSCM_d" = numeric(), 
                         "Notes" = character(), stringsAsFactors = F,FZ_Charrassin_2008 = character(),FZ_SokolovArgo = character())
  ## This needs to go through synthesised chlorophyll values later - with corrections employed
  # for(ex in expos){
    # set up directory adresses
    # HPLC_file = file.path(data_path,ex,"HPLC","reformatted",paste(ex,"HPLC.csv",sep = "_"))
    # CHL_file = file.path(data_path,ex,"Fluorometry","reformatted",paste(ex,"CHL.csv",sep = "_"))
    # Get chlorophyll data 
    
    # if(file.exists(HPLC_file)){
    #   
    #   f <- file(HPLC_file, open = "r" )
    #   lines = readLines( f, 50L, skipNul = T )
    #   close(f)
    #   n = which(grepl("CTD_ID",lines) ==T)
    #   
    #   chl_data = fread(HPLC_file,skip = n+1, header = F,na.strings = "-999")
    #   colnames(chl_data) = as.character(fread(HPLC_file, stringsAsFactors = F, skip = n-1, nrows = 1, header = F))
    #   colnames(chl_data)[which(colnames(chl_data) == "TOT_CHL_A")] = "CHLORA"
    #   
    #   }else{
    #     if(file.exists(CHL_file)){
    #       
    #       f <- file(CHL_file, open = "r" )
    #       lines = readLines( f, 50L, skipNul = T )
    #       close(f)
    #       n = which(grepl("CTD_ID",lines) ==T)  
    #       
    #       chl_data = fread(CHL_file,skip = n+1, header = F,na.strings = "-999")
    #       colnames(chl_data) = as.character(fread(CHL_file, stringsAsFactors = F, skip = n-1, nrows = 1, header = F))
    #       }else{stop(paste("There is no chlorophyll data for", ex))}
    #   }
    
    #pig_data =pig_data %>% mutate(CHLORA_best = ifelse(test = is.na(TOT_CHL_A), yes = CHLORA, no = TOT_CHL_A))
    # filter out underway data
    chl_data = pig_data %>% filter(STNNBR != "U", is.finite(DEPTH))
    # get CTD_ID list
    for(ctd in CTD_IDs){
      # select pigment data that is for that ctd ID
      chl_ctd_data = chl_data %>% filter(CTD_ID == ctd)
      
      # check to see if HPLC and chlora overlap (and there are at least 4 HPLC measurements)
      n_hplc = length(is.finite(chl_ctd_data$TOT_CHL_A))
      n_chl = length(is.finite(chl_ctd_data$CHLORA))
      
      if(n_chl > n_hplc & n_hplc <= 4){sub_chl_data = chl_ctd_data %>% filter(is.finite(CHLORA))
      sub_chl_data = sub_chl_data %>% mutate(best_CHLORA = CHLORA)}else{
        sub_chl_data = chl_ctd_data %>% filter(is.finite(TOT_CHL_A))
        sub_chl_data = sub_chl_data %>% mutate(best_CHLORA = TOT_CHL_A)
      }
      
      
      idx = nrow(prof_data) + 1
      prof_data[nrow(prof_data)+1,] <- NA
      prof_data$CTD_ID[idx] = ctd
      CTD_file = file.path("E:/Data_Aggregation_layers/profiling_sensors",paste(ctd,"ctd1.csv",sep = "_"))
      
      f <- file(CTD_file, open = "r" )
      lines = readLines( f, 50L, skipNul = T )
      close(f)
      n = which(grepl("CTDPRS",lines) ==T)  
      
      ctd_data = fread(CTD_file,skip = n+1, header = F,na.strings = "-999")
      colnames(ctd_data) = as.character(fread(CTD_file, stringsAsFactors = F, skip = n-1, nrows = 1, header = F))
      ctd_data = ctd_data[rowSums(!is.na(ctd_data) | (ctd_data != "")) > 1,]
      ctd_data$CTDSAL = as.numeric(ctd_data$CTDSAL)
      ctd_data$CTDPRS = as.numeric(ctd_data$CTDPRS)
      ctd_data$CTDTMP = as.numeric(ctd_data$CTDTMP)
      
     
   
      
      prof_data[idx,c("DATE","TIME","TIME_QF")] = sub_chl_data[1,c("DATE","TIME_analyser","TIME_QF")]
      prof_data$LAT[idx] = as.numeric(sub_chl_data[1,c("LATITUDE")])
      prof_data$LON[idx] = as.numeric(sub_chl_data[1,c("LONGITUDE")])
      prof_data$YYYY[idx] = as.numeric(substr(prof_data$DATE[idx],1,4))
      prof_data$MM[idx] = as.numeric(substr(prof_data$DATE[idx],6,7))
      prof_data$DD[idx] = as.numeric(substr(prof_data$DATE,9,10))
      
      if(is.na(prof_data$LAT[idx])){
        prof_data$LAT[idx] = as.numeric(sub_chl_data$LAT_analyser[1])
        prof_data$LON[idx] = as.numeric(sub_chl_data$LON_analyser[1])
        prof_data$LAT_LON_POS[idx] = "analyser"}

      prof_data$nobs[idx] = length(sub_chl_data$best_CHLORA)
      prof_data$min_d[idx] = min(sub_chl_data$DEPTH)
      prof_data$max_d[idx] = max(sub_chl_data$DEPTH)
      
      
      
      

      
      
      
      # SCM
      prof_data$surf_val[idx] = max(sub_chl_data$best_CHLORA[which(sub_chl_data$DEPTH <= 15)])
      if((prof_data$surf_val[idx] + 0.2) < max(sub_chl_data$best_CHLORA,na.rm = T) & prof_data$surf_val[idx] < 1)
      {
        prof_data$SCM[idx] = "Y"
        prof_data$SCM_d[idx] = sub_chl_data$DEPTH[which.max(sub_chl_data$best_CHLORA)]
        prof_data$SCM_val[idx] = max(sub_chl_data$best_CHLORA,na.rm = T)
        if(prof_data$SCM_d[idx] <= 15){prof_data$SCM[idx] = "N"
        prof_data$SCM_d[idx] = NA
        prof_data$SCM_val[idx] = NA }
      }else{if((1.2*prof_data$surf_val[idx]) < max(sub_chl_data$best_CHLORA,na.rm = T) &  prof_data$surf_val[idx] > 1){
        prof_data$SCM[idx] = "Y"
        prof_data$SCM_d[idx] = sub_chl_data$DEPTH[which.max(sub_chl_data$best_CHLORA)]
        prof_data$SCM_val[idx] = max(sub_chl_data$best_CHLORA,na.rm = T)
        if(prof_data$SCM_d[idx] <= 15){prof_data$SCM[idx] = "N"
        prof_data$SCM_d[idx] = NA
        prof_data$SCM_val[idx] = NA }
      }else{prof_data$SCM[idx] = "N"}}
      
      
      ## Calculations for water column structure
      # middle of the pycnocline (point of greatest gradient)
      ### Front classes
      # Charasin
      prof_data$FZ_Charrassin[idx] = front_Charrassin2008(ctd_data$CTDPRS, ctd_data$CTDTMP)
      
      #SORARC
      prof_data$FZ_sorarc[idx] = front_class_sorarc(ctd_data$CTDPRS, ctd_data$CTDTMP, ctd_data$CTDSAL)
      
      #SOkolov_Argo
      prof_data$FZ_SokolovArgo[idx] = front_class_Sokolov2009_theta(ctd_data$CTDPRS, ctd_data$CTDTMP, ctd_data$CTDSAL,prof_data$LAT[idx],prof_data$LON[idx] )
      
      prof_data$FZ_insitu[idx] = front_class_insitu(ctd_data$CTDPRS, ctd_data$CTDTMP, ctd_data$CTDSAL,prof_data$LAT[idx],prof_data$LON[idx] )
      
      
      
      ctd_data$DENS = as.numeric(rho(S = ctd_data$CTDSAL, T = ctd_data$CTDTMP, P = 0))
      if(length(which(is.nan(ctd_data$DENS) == T)) > 0){ctd_data$DENS[which(is.nan(ctd_data$DENS))] = NA }
      if(length(which(is.finite(ctd_data$DENS) == T)) == 0){prof_data$Notes[idx] = paste("CTD ID", ctd, "is missing all density. Salinity might be missing from old data.")
      next}
      ctd_data$DENS_s = ctd_data$DENS
      ctd_data$DENS_s[is.finite(ctd_data$DENS)] = runmed(ctd_data$DENS[is.finite(ctd_data$DENS)], 3)
      
      ## MLD 
      # use linear interpolation for now but look into using a smoothing fit
      ctd_data$DEPTH_gws = swDepth(ctd_data$CTDPRS, latitude = prof_data$LAT[idx])
      prof_data$CTD_max_d[idx] = max(ctd_data$DEPTH_gws, na.rm = T)
      prof_data$CTD_min_d[idx] = min(ctd_data$DEPTH_gws, na.rm = T)
            if(length(which(ctd_data$DEPTH_gws >= 10)) <3){prof_data$Notes[idx] = paste("CTD ID", ctd,"is too shallow")
      next}
      
      if(length(which(ctd_data$DEPTH_gws >= 10)) <3 & min(ctd_data$DEPTH_gws,na.rm = T) < 50){prof_data$Notes[idx] = paste("is too shallow, assume homogeneous UML for MLD (up to 50m allowed)")
      DENS_10 = mean(DENS_s[which(ctd_data$DEPTH_gws == min(ctd_data$DEPTH_gws,na.rm = T))],na.rm = T)
      }else{
        DENS_10 = approx(x = ctd_data$DEPTH_gws, y = ctd_data$DENS_s, xout = 10)$y}
      

      if(is.na(DENS_10)){
        prof_data$Notes[idx] = paste("CTD ID", ctd, "is missing a surface density - most likeley due to missing surface measurments")
        jpeg(file.path("C:/Users/kabaldry/Documents/PhD/Introduction_review/Results/MLD and TLD plots",paste(ctd,".jpg")))
        par(mfrow= c(1,3))
        plot(ctd_data$DENS,ctd_data$DEPTH_gws, ylim = c(500,0))
        plot(ctd_data$CTDSAL,ctd_data$DEPTH_gws, col = "green",ylim = c(500,0))
        plot(ctd_data$CTDTMP,ctd_data$DEPTH_gws, col = "blue",ylim = c(500,0))
        dev.off()
        next}

      MLD = approx(x = ctd_data$DENS_s[which(ctd_data$DEPTH_gws >= 10)], y = ctd_data$DEPTH_gws[which(ctd_data$DEPTH_gws >= 10)], xout = DENS_10 + 0.03)$y
      
      if(prof_data$nobs[idx] < 4 | prof_data$min_d[idx] > 15 | length(which(sub_chl_data$DEPTH > 20)) < 3){
        prof_data$in_Analysis[idx] = "N"
        next}else{prof_data$in_Analysis[idx] = "Y"}
      
      
      
      
      # calculate the middle of the pycnocline
      # average to 2m bins
      DEPTH_bins = seq(0, max(ctd_data$DEPTH_gws,na.rm = T), by=2)
      DENS_bins = tapply(ctd_data$DENS_s, cut(ctd_data$DEPTH_gws, DEPTH_bins), function(x){median(x, na.rm = T)})
      # readjust bin values to middle
      DEPTH_bins = seq(0, max(ctd_data$DEPTH_gws,na.rm = T), by=2)[1:length(DEPTH_bins)-1] + 1
      # interpolate NA's
      if(length(which(is.na(DENS_bins)==T))){
        
      DENS_bins[which(is.na(DENS_bins))] = approx(y = DENS_bins, x = DEPTH_bins, xout = DEPTH_bins[which(is.na(DENS_bins))])$y}
  
          # QI - M
      QIM =function(l,m,u){
        if(l %% 2 == 0){l = l-1}
        idx1 = which(DEPTH_bins %in% seq(l,m,2))
        idx2 = which(DEPTH_bins %in% seq(l,u,2))
        1 - ( (sd(DENS_bins[idx1] - mean(DENS_bins[idx1], na.rm = T), na.rm = T)) / (sd(DENS_bins[idx2] - mean(DENS_bins[idx2], na.rm = T), na.rm = T)))}
        
      if(length(which(is.finite(DENS_bins[1:5]))) > 2 ){
        if(QIM(0,10,15) < 0.6 & (ctd_data$CTDSAL[which(is.finite(ctd_data$CTDSAL) ==T)[1]] - ctd_data$CTDSAL[which.closest(ctd_data$DEPTH_gws,10)[1]] ) < -0.1 ){prof_data$FWL[idx] = "Y"}else{prof_data$FWL[idx] = "N"}}
      
        if(is.na(MLD)){
          prof_data$Notes[idx] = paste(prof_data$Notes[idx] ,paste("CTD ID",ctd, "MLD is not defined likeley due to FWL or shallow profile"), sep = "|")
          jpeg(file.path("C:/Users/kabaldry/Documents/PhD/Introduction_review/Results/MLD and TLD plots",paste(ctd,".jpg")))
          par(mfrow= c(1,3))
          plot(ctd_data$DENS,ctd_data$DEPTH_gws, ylim = c(500,0))
          plot(ctd_data$CTDSAL,ctd_data$DEPTH_gws, col = "green",ylim = c(500,0))
          plot(ctd_data$CTDTMP,ctd_data$DEPTH_gws, col = "blue",ylim = c(500,0))
          dev.off()
        next}
  
      prof_data$MLD[idx] = MLD
      prof_data$QI_MLD[idx] = QIM(10,MLD,1.5*MLD)
  
          
      
      ## TLD
      # QI - Transition Layer    
      # interpolate to increase resolution in density gradient
      interp_DEPTH_DENS = approx(x = DEPTH_bins, y = DENS_bins, xout = seq(1,max(DEPTH_bins),0.5))
  
      QIT =function(l,m,u){
        l = l + (0.5- (l %% 0.5))
        m = m + (0.5- (m %% 0.5))
        idx1 = which(interp_DEPTH_DENS$x %in% seq(m,u,0.5))
        idx2 = which(interp_DEPTH_DENS$x %in% seq(l,u,0.5))
        1 - ( (sd(interp_DEPTH_DENS$y[idx1] - mean(interp_DEPTH_DENS$y[idx1], na.rm = T))) / (sd(interp_DEPTH_DENS$y[idx2] - mean(interp_DEPTH_DENS$y[idx2], na.rm = T))))}
      
      if(MLD + (0.5- (MLD %% 0.5))+2 > max(interp_DEPTH_DENS$x)){prof_data$Notes[idx] = paste(prof_data$Notes[idx] ,paste("CTD ID", ctd, "is too shallow or is highly stratified"), sep = "|")}else{
      for(dp in seq(MLD + (0.5- (MLD %% 0.5))+2, max(interp_DEPTH_DENS$x),0.5)){
        if(dp + 20 > max(interp_DEPTH_DENS$x)){
          prof_data$Notes[idx] = paste(prof_data$Notes[idx] ,paste("CTD ID", ctd, "is too shallow or is highly stratified"), sep = "|")
          break}
        QI_TLD = QIT(MLD,dp,dp + 20)
        if(is.nan(QI_TLD)){next}
        if(QI_TLD > 0.8){prof_data$TLD[idx] = dp
        prof_data$QI_TLD[idx] = QI_TLD
        break}
        
        
          
        
        
      }
      
             }
      jpeg(file.path("C:/Users/kabaldry/Documents/PhD/Introduction_review/Results/MLD and TLD plots",paste(ctd,".jpg")))
      par(mfrow= c(1,3))
      plot(interp_DEPTH_DENS$y,interp_DEPTH_DENS$x, ylim = c(500,0))
      abline(h = prof_data$MLD[idx], col = "red")
      abline(h = prof_data$TLD[idx], col = "black")
      plot(ctd_data$CTDSAL,ctd_data$DEPTH_gws, col = "green",ylim = c(500,0))
      plot(ctd_data$CTDTMP,ctd_data$DEPTH_gws, col = "blue",ylim = c(500,0))

      dev.off()
      
      rm(list = setdiff(ls(), c("front_class_sorarc","front_class_Sokolov2009_theta","front_Charrassin2008","data_path","idx","prof_data","CTD_IDs","chl_data", "sub_chl_data","ctd","front_class_insitu")))
      
      
      
      
      
      

      
      # Normalised, gridded profiles
      
      # Unnormalised, gridded profiles
      
      # Front Zone
      
    }
    rm(list = setdiff(ls(), c("front_class_sorarc","front_class_Sokolov2009_theta","front_Charrassin2008","data_path","expo_list","idx","prof_data","front_class_insitu")))
    
        
    
 
  write.csv(prof_data,file.path("C:/Users/kabaldry/Documents/PhD/Introduction_review/Data","prof_data_03022020.csv")) 
   
  # m1 = lm(FLUOR[1:sp]~PRES_optic[1:sp])$coefficients[2]}
  # m2 = lm(FLUOR[sp:(sp+window)]~PRES_optic[sp:(sp+window)])$coefficients[2]
  # tan_theta[[sp]] = (m2 - m1)/(1+(m2*m1))}
  # tan_theta = unlist(tan_theta)
  # MAM_MLD = which(tan_theta == max(tan_theta,na.rm = T))