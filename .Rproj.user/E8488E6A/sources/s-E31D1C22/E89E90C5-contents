---
title: "BIO-MATE.v0"
output: html_notebook
author: K. Baldry
---

### load required functions
```{r}
library(dplyr)
library(tools)
library(data.table)
library(ncdf4)
library(readr)
library(geosphere)
library(stringi)
library(tidyr)
library(devtools)
#devtools::install_github("KimBaldry/BIO-MATE/Rpackage")
library(BIOMATE)
BIOMATE::add_bibstyle()
```

# Split large data files from various sources
### Old Southern Surveyor data
split some old Marlin Southern Surveyor files and record data amendment
```{r}
SS_CTDsplit("E:/Data_downloads/Marlin")
```

### Marlin data trawler
Split some Marlin CTD data into stations as CSIRO Data Trawler had a bug.
Bug was reported to CSIRO and fixed.
CSIRO Data Trawler station splitting feature can be used in the future.
```{r}
files = c("MNF_FR199710_ctd_trawler.csv",
  "O&A_SS199603_ctd_trawler.csv",
  "MNF_IN2016_V01_ctd_trawler.csv",
  "MNF_IN2016_V02_ctd_trawler.csv",
  "MNF_IN2016_V03_ctd_trawler.csv",
  "MNF_IN2018_V01_ctd_trawler.csv")
expos = c("09FA19971125",
  "09SS19960513",
  "096U20160107",
  "096U20160314",
  "096U20160426",
  "096U20180110"
)
for(ex in 1:length(expos)){
  split_compiled_delim_file(path = file.path("E:/Data_downloads/Marlin",expos[ex]), file_name = files[ex], delim = ",",expo_split = F,station_split = T, station_var_name = "STATION")
}

```


### PALMER LTER
split files by EXPOCODE synonyms

CTD files
```{r}
split_compiled_delim_file(path = "E:/Data_downloads/PAL-LTER/CTD", file_name = "CTD Downcast Data (Cruise).csv", delim = ",",synonym_var_name = "studyName",station_split = T, station_var_name = "Event.Number")
```
 CHL and HPLC files
```{r}
split_compiled_delim_file(path = "E:/Data_downloads/PAL-LTER/pigments/CHL", file_name = "Chlorophyll (Cruise).csv", delim = ",",synonym_var_name = "studyName",station_split = F, fillcell = T)

split_compiled_delim_file(path = "E:/Data_downloads/PAL-LTER/pigments/HPLC", file_name = "High Performance Liquid Chromatography Pigments.csv", delim = ",",synonym_var_name = "studyName",station_split = F)
```

Fix 33LG20070101 HPLC depths by inserting from phaeopigment file
```{r}
# read in phaeo file
chl = read.csv("E:/Data_downloads/PAL-LTER/pigments/CHL/33LG20070101/33LG20070101_from_Chlorophyll (Cruise).csv" , stringsAsFactors = F, header = T)
# read in HPLC file
hplc = read.csv("E:/Data_downloads/PAL-LTER/pigments/HPLC/33LG20070101/33LG20070101_from_High Performance Liquid Chromatography Pigments.csv", stringsAsFactors = F, header = T)
hplc = hplc[,-which(colnames(hplc) == "Depth")]
#match and fill
chl = chl[,c("Event","Bottle","Depth")]
hplc = left_join(hplc,chl,by = c("Event","Bottle"))
# rewrirte HPLC file
write.csv(x = hplc,file = "E:/Data_downloads/PAL-LTER/pigments/HPLC/33LG20070101/33LG20070101_from_High Performance Liquid Chromatography Pigments.csv",row.names = F)
```


### PANGEA CTD data

split into station files
```{r}
dirs = list.dirs("E:/Data_downloads/PANGEAE",full.names = T, recursive = F)
for(dr in dirs){
  if(all(!grepl(file.path(dr,"ctd"), list.dirs(file.path(dr))))){next}
  if(dr == "35XI20090905"){next}
  fname = list.files(file.path(dr,"ctd"),pattern = ".tab", full.names = T)
  # find the line where the data table starts
  f <- file( fname, open = "r" )
  n=0
  while( TRUE ){
    line <- readLines( f, 1L )
    n = n+1
    if(grepl(pattern = "\\*\\/" ,x = line)){
      ls = n +1
      break
    }
  }
  close( f )

split_delim_file(path = file.path(dr,"ctd"), file_name = basename(fname), delim = "\t" , expo_split = F, station_var_name = "Event",station_split = T, fillcell = T, line_start = ls)  
print(dr)

}
```

filter and split TARA oceans ctd 
```{r}
file_name = "TARA_physical.tab"
path = "E:/Data_downloads/TARA_PANGEAE/35XI20090905/ctd"
delim = "\t"

data = read.table(file = file.path(path,file_name), header = T, sep = delim, skip = 0, stringsAsFactors = F, strip.white = T,fill = T)

data = data %>% filter(Station != "")
for(sn in unique(data$Station)){
  sub_data = data %>% dplyr::filter(data[,"Station"] == sn)
  write.csv(sub_data, file = file.path(path,"split",paste("35XI20090905","_",sn,"_from_", "TARA_physical",".csv", sep = "")), row.names = F)
}


```


# Something is wrong with a couple of profiles
```{r}
dir = "E:/Data_downloads/PANGEAE/06AQ19881122/ctd/split"

for(sp in c("PS141712_from_ANT-VII_3_phys_oce.csv","PS141521_from_ANT-VII_3_phys_oce.csv")){
  data = read.csv(file.path(dir,sp), stringsAsFactors = F,header = T)
  data2 = aggregate(data[,6:10],by = list(data$Depth),FUN = function(x){mean(x,na.rm =T)})
  data3 = data[unique(data$Depth),]
  data3[,6:10] = data2[2:6]
  write.csv(data3,file.path(dir,sp),row.names = F)
}
```


# L'Astrolabe underway data
Split by EXPOCODE synonyms
```{r}
split_compiled_delim_file(path = "E:/Data_downloads/IMOS/L'Astrolabe/underway", file_name = "Fast_Repetition_Rate_Fluorometry_(FRRF)_data_collected_on_the_RV_L'Astrolabe.csv", delim = "," , expo_split = T, synonym_var_name = "file_id",station_split = F, fillcell = T)
```

# MGDS ctd data
These files do not have a header line. Insert a header line above the data frame
```{r}
heads = fread("E:/Data_downloads/MGDS/Missing_headers.csv", header = T)

for(sp in 1:length(heads$EXPOCODE))
{
  files = list.files(heads$path[sp], pattern = ".cnv", full.names = T)
  for(fname in files){
  new_file_path =   file.path(heads$path[sp],"adapted",paste("heads_insert_",basename(fname), sep = ""))
  if(!file.exists(file.path(heads$path[sp],"adapted"))){dir.create(file.path(heads$path[sp],"adapted"))}
  
  f <- file( fname, open = "r" )
  n=0
  while( TRUE ){
    line <- readLines( f, 1L )
    n = n+1
    if(grepl(pattern = "\\*END\\*" ,x = line)){
    
    break
    }
  }
  close( f )
  
  f <- file( fname, open = "r" )
  fd <- file(new_file_path, open = "wt")
  writeLines(readLines(f,n),fd)
  h = heads[sp,3:24]
  l = !unlist(lapply(h, FUN = is.empty))
  h = as.character(h)[l]
  writeLines(paste(h, collapse = "\t", sep = ""),fd)
  writeLines(readLines(f,-1L),fd)
  close( f )
  close(fd)
  tf = file(file.path(heads$path[sp],"adapted",paste("Data_amendments",Sys.Date(),".txt", sep = "")),open = "wt")
      writeLines(paste("A header line was inserted into",fname),tf)
close(tf)
  }
}
```

# GLODAPv2.2020
Split GLODAPv2.2020 by cruise IDs
```{r}
GLODAP_df = fread("E:/Data_downloads/GLODAP/GLODAPv2.2020_Merged_Master_File.csv")
colnames(GLODAP_df) = sub( "G2", "",colnames(GLODAP_df))
for(ex in unique(GLODAP_df$cruise))
{
  ex_df = GLODAP_df %>% filter(cruise == ex)
  ex_dir = file.path("E:/Data_downloads/GLODAP", ex)
  if(!file.exists(ex_dir))
    {dir.create(ex_dir)}

  write.csv(ex_df, paste(ex_dir, "/GLODAPv2.2020_split_",ex,".csv", sep = ""), row.names = F)
}

```

# MAREDAT
Split MAREDAT by cruise IDs
```{r}
MAREDAT_df = fread("E:/Data_downloads/MAREDAT/MAREDAT_pigments_master_file_Updated210313.csv")
MAREDAT_df = MAREDAT_df %>% filter(Cruise_des %in% c(18,47,119:122))
for(ex in unique(MAREDAT_df$Cruise_des))
{
  ex_df = MAREDAT_df %>% filter(Cruise_des == ex)
  ex_dir = file.path("E:/Data_downloads/MAREDAT", ex)
  if(!file.exists(ex_dir))
    {dir.create(ex_dir)}

  write.csv(ex_df, paste(ex_dir, "/MAREDAT.2019_split_",ex,".csv", sep = ""), row.names = F)
}

```

# JGOFS data
Insert cast_type into ctd data so that match ups can be performed on pigment data
```{r}
for(dir in list.dirs("E:/Data_downloads/JGOFS", recursive = F)){
  subdirs = list.dirs(dir, recursive = F)
  # create new directory for edited files
  if(!dir.exists(file.path(dir, "all_ctd")))
    {dir.create(file.path(dir, "all_ctd"))}
  # edit files and save to new directory
  if(file.path(dir, "TMctd") %in% subdirs){
    # add CTD to new variable cast_type in CTD files
    for(fl in list.files(file.path(dir, "ctd"), pattern = ".csv")){
      data = as.data.frame(fread(file.path(dir, "ctd",fl),stringsAsFactors = F,strip.white = T, header = T, keepLeadingZeros = T))
      data$cast_type = "CTD"
      write.csv(data,file.path(dir, "all_ctd",fl), row.names = F)
    }
    # add TM to new variable cast_type in TMctd files
    for(fl_tm in list.files(file.path(dir, "TMctd"), pattern = ".csv")){
      data = as.data.frame(fread(file.path(dir, "TMctd",fl_tm),stringsAsFactors = F,strip.white = T, header = T, keepLeadingZeros = T))
      data$cast_type = "TM"
      write.csv(data,file.path(dir, "all_ctd",paste("TM",fl_tm)), row.names = F)
    }
  }
}
```


# SISMER data
```{r}
expos = c("35MF19940126", "35MF19950927", "35MF19980121", "35MF20040103")
for(ex in expos){
  path = paste("E:/Data_downloads/SISMER", ex, "ctd", sep = "/")
  fname = list.files(path, pattern = "*.txt")
  fl = file.path(path,fname)
 
  f <- file( fl, open = "r" )
      n = 0
      while( TRUE ){
        line <- readLines( f, 1L )
        n = n+1
        if(BIOMATE::is.empty(line)){next}
        if(substr(line,1,2) != "//"){break}
      }
      close(f)

  data = read.table(file = fl, header = T, sep = "\t", stringsAsFactors = F, strip.white = T,fill = T, skip = n-1)
  
  # change header names 
  if(ex == "35MF19940126" | ex == "35MF19950927"){
  colnames(data)[c(4,5,6,10,12,14,16)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL", "DOXY")}
  if(ex == "35MF19980121"){colnames(data)[c(4,5,6,10,14,16)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL")}
  if(ex == "35MF20040103"){colnames(data)[c(4,5,6,10,14,16,18)] = c("TIME","LATITUDE", "LONGITUDE","PRES", "TEMP", "PSAL","FLUOR")}
  
  # split according to finite station type
  idx = which(is.finite(data$Station))
  for(st in 1:length(idx)){
    if(st == length(idx)){sub_data = data[idx[st]:length(data),]}else{sub_data = data[idx[st]:(idx[st+1]-1),]}
    
  
    # fill in missing values
    sub_data[,c("Cruise","Station", "TIME", "LATITUDE", "LONGITUDE")] = sub_data[1,c("Cruise","Station", "TIME", "LATITUDE", "LONGITUDE")]
    
    # save file in new split directory
    write.csv(sub_data, file.path(paste("E:/Data_downloads/SISMER", ex, "ctd","split", sep = "/"), paste(ex,"ctd_", sub_data$Station[1],".csv", sep = "")), row.names = F )
  }
  
}
```



# Reformat Files
Bulk run
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
chunks = c("regression_test", "C1", "C2", "C3", "C4")

for(ch in chunks[2:5]){
  PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"processing_metadata",ch),userID = "IMASUTASKB")

  PIG_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"processing_metadata",ch),userID = "IMASUTASKB")
}

```


## REGRESSION TEST
### reformat profiling_sensor files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE"
PROF_to_WHPE(path_out = file.path(path,"BIO-MATE","product_data","regression_test","reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","regression_test"),userID = "IMASUTASKB") 
```

### reformat pigment files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE"
PIG_to_WHPE(path_out = file.path(path,"BIO-MATE","product_data","regression_test","reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","regression_test"),userID = "IMASUTASKB")
```

## Cluster 0
### reformat profiling_sensor files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
BIOMATE::PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","regression_test"),userID = "IMASUTASKB") 
```

### reformat pigment files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
PIG_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","regression_test"),userID = "IMASUTASKB")
```

## Cluster 1
### reformat profiling_sensor files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C1"),userID = "IMASUTASKB") 
```

### reformat pigment files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
PIG_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C1"),userID = "IMASUTASKB")
```

## Cluster 2
### reformat profiling_sensor files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C2"),userID = "IMASUTASKB")
```

### reformat pigment files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
PIG_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C2"),userID = "IMASUTASKB")
```

## Cluster 3
### reformat profiling_sensor files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C3"),userID = "IMASUTASKB", row_start = 2, row_end = 2)
```

### reformat pigment files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
PIG_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C3"),userID = "IMASUTASKB")
```

## Cluster 4
### reformat profiling_sensor files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE"
PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C4"),userID = "IMASUTASKB", row_start = 14)
```

### reformat pigment files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
PIG_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C4"),userID = "IMASUTASKB", row_start = 1)
```

## Cluster 5
### reformat profiling_sensor files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
BIOMATE::PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C5"),userID = "IMASUTASKB", row_start =12, row_end = 12 )
```

### reformat pigment files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
PIG_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","product_data","processing_metadata","C5"),userID = "IMASUTASKB",row_start = 49)
```

## Cluster 6
### reformat profiling_sensor files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/BIO-MATE.v0"
PROF_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","processing_metadata","C6"),userID = "IMASUTASKB", row_start = 14)
```

### reformat pigment files
```{r}
path = "C:/Users/kabaldry/OneDrive - University of Tasmania/Documents/Projects/BIO-MATE/"
PIG_to_WHPE(path_out = file.path(path,"reformatted_data"), file_path = file.path(path,"BIO-MATE","processing_metadata","C6"),userID = "IMASUTASKB", row_start = )
```
